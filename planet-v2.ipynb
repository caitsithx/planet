{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "\n",
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chicm/data/planet'\n",
    "RESULT_DIR = DATA_DIR + '/resultsv2'\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(DATA_DIR+'/train_v2.csv')\n",
    "df_test = pd.read_csv(DATA_DIR+'/sample_submission_v2.csv')\n",
    "\n",
    "classes = ['clear', 'haze', 'partly_cloudy', 'cloudy', \n",
    "           'primary', 'agriculture', 'water', 'cultivation', 'habitation', 'road',\n",
    "            'slash_burn', 'conventional_mine', 'bare_ground', 'artisinal_mine', \n",
    "           'blooming', 'selective_logging', 'blow_down']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flatten = lambda l:[item for sublist in l for item in sublist]\n",
    "t = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_map = {l: i for i, l in enumerate(classes)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "print(inv_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_size = (224, 224)\n",
    "\n",
    "def get_train_data(start, end):\n",
    "    x_train_list = []\n",
    "    y_train_list = []\n",
    "\n",
    "    for f, tags in tqdm(df_train.values[start:end]):\n",
    "        fn = DATA_DIR+'/train-jpg/'+f+'.jpg'\n",
    "        img = cv2.imread(fn) \n",
    "        targets = np.zeros(17)\n",
    "        for t in tags.split(' '):\n",
    "            targets[label_map[t]] = 1\n",
    "        x_train_list.append(cv2.resize(img, img_size)) \n",
    "        y_train_list.append(targets)\n",
    "        \n",
    "    x_train = np.array(x_train_list)\n",
    "    y_train = np.array(y_train_list)\n",
    "    print(x_train.shape) \n",
    "    print(y_train.shape)\n",
    "    return x_train,y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df_train[:5])\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(32,32))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(x_train[26])\n",
    "plt.title(y_train[26])\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(x_train[273])\n",
    "plt.title(y_train[273])\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(x_train[290])\n",
    "plt.title(y_train[290])\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(x_train[412])\n",
    "plt.title(y_train[412])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_train(x_train, y_train):\n",
    "    split_percent = 0.85\n",
    "    split = int(x_train.shape[0] * split_percent)\n",
    "    x_val = x_train[split:]\n",
    "    y_val = y_train[split:]\n",
    "    x_train = x_train[:split]\n",
    "    y_train = y_train[:split]\n",
    "    print(x_val.shape, y_val.shape, x_train.shape, y_train.shape)\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.mean(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05, \n",
    "        horizontal_flip=True,\n",
    "        vertical_flip = True,\n",
    "        rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers import Activation\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "res50 = applications.ResNet50(include_top=False, weights='imagenet',input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model(input_shape):\n",
    "    fc_model = Sequential()\n",
    "    fc_model.add(Flatten(input_shape=input_shape))\n",
    "    #fc_model.add(Dense(256, activation='relu'))\n",
    "    #fc_model.add(Dropout(0.6))\n",
    "    fc_model.add(Dense(17, activation='sigmoid'))\n",
    "    return fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=res50.input, outputs=get_fc_model(res50.output_shape[1:])(res50.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "def lr_schedule(epoch):\n",
    "    if epoch <= 10:\n",
    "        return 0.001\n",
    "    elif epoch <= 20:\n",
    "        return 0.0001\n",
    "    else: \n",
    "        return 0.00005\n",
    "    \n",
    "w_filename = RESULT_DIR + '/res50_224.h5'\n",
    "callbacks = [ EarlyStopping(monitor='val_loss', patience=40, verbose=0),\n",
    "              ModelCheckpoint(w_filename, monitor='val_loss', save_best_only=True, verbose=0),\n",
    "              LearningRateScheduler(lr_schedule)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ranges = [[0, 10000], [10000, 20000], [20000, 30000], [30000, 40480]]\n",
    "\n",
    "for rng in ranges:\n",
    "    x_train, y_train = get_train_data(rng[0], rng[1])\n",
    "    x_train, y_train, x_val, y_val = split_train(x_train, y_train)\n",
    "    model.fit_generator(\n",
    "        train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=test_datagen.flow(x_val, y_val, batch_size=batch_size), \n",
    "        validation_steps=x_val.shape[0] // batch_size,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(w_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.max(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_val = x_val / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.mean(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_val = model.predict(x_val, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(pred_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimise_f2_thresholds(y, p, verbose=True, resolution=100):\n",
    "    def mf(x):\n",
    "        p2 = np.zeros_like(p)\n",
    "        for i in range(17):\n",
    "            p2[:, i] = (p[:, i] > x[i]).astype(np.int)\n",
    "        score = fbeta_score(y, p2, beta=2, average='samples')\n",
    "        return score\n",
    "\n",
    "    x = [0.18] * 17\n",
    "    for i in range(17):\n",
    "        best_i2 = 0\n",
    "        best_score = 0\n",
    "        for i2 in range(resolution):\n",
    "            i2 /= resolution\n",
    "            x[i] = i2\n",
    "            score = mf(x)\n",
    "            if score > best_score:\n",
    "                best_i2 = i2\n",
    "                best_score = score\n",
    "        x[i] = best_i2\n",
    "        if verbose:\n",
    "            print(i, best_i2, best_score)\n",
    "\n",
    "    for i in range(17):\n",
    "        best_i2 = 0\n",
    "        best_score = 0\n",
    "        for i2 in range(resolution):\n",
    "            i2 /= resolution\n",
    "            x[i] = i2\n",
    "            score = mf(x)\n",
    "            if score > best_score:\n",
    "                best_i2 = i2\n",
    "                best_score = score\n",
    "        x[i] = best_i2\n",
    "        if verbose:\n",
    "            print(i, best_i2, best_score)\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thr = optimise_f2_thresholds(y_val, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thr = [0.2, 0.25, 0.12, 0.09, 0.31, 0.13, 0.18, 0.26, 0.26, 0.21, 0.32, 0.28, 0.18, 0.16, 0.24, 0.19, 0.33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "import glob\n",
    "\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(DATA_DIR+'/sample_submission_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = np.zeros((df_test.values.shape[0], 17))\n",
    "index = 0\n",
    "for f, tags in tqdm(df_test.values):\n",
    "    fn = DATA_DIR+'/test-jpg/'+f+'.jpg'\n",
    "    if not os.path.isfile(fn):\n",
    "        fn = DATA_DIR+'/test-jpg-add/'+f+'.jpg'\n",
    "    img = cv2.imread(fn)\n",
    "    #x_test.append(cv2.resize(img, img_size))\n",
    "    #x_test[index] = img / 255.\n",
    "    img = img/255.\n",
    "    x_test = np.expand_dims(img, axis=0)\n",
    "    preds[index] = model.predict(x_test)\n",
    "    index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(RESULT_DIR+'/preds.dat', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_multi_classes(score, threshold, nil=''):\n",
    "    N = len(classes)\n",
    "    s = nil\n",
    "    for n in range(N):\n",
    "        if score[n] > threshold[n]:\n",
    "            if s == nil:\n",
    "                s = classes[n]\n",
    "            else:\n",
    "                s = '%s %s' % (s, classes[n])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, pred in enumerate(preds):\n",
    "    tags = get_multi_classes(pred, thr)\n",
    "    df_test['tags'][i] = tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.to_csv(RESULT_DIR+'/sub1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nfolds = 6\n",
    "batch_size = 128\n",
    "\n",
    "num_fold = 0\n",
    "sum_score = 0\n",
    "\n",
    "kf = KFold(len(y_train), n_folds=nfolds, shuffle=True, random_state=1)\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "        start_time_model_fitting = time.time()\n",
    "        \n",
    "        X_train = x_train[train_index]\n",
    "        Y_train = y_train[train_index]\n",
    "        X_valid = x_train[test_index]\n",
    "        Y_valid = y_train[test_index]\n",
    "\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        print('Split train: ', len(X_train), len(Y_train))\n",
    "        print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "        \n",
    "        w_filename = RESULT_DIR + '/wconv_' + str(num_fold) + '.h5'\n",
    "        \n",
    "        model = get_model()\n",
    "        \n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "            ModelCheckpoint(w_filename, monitor='val_loss', save_best_only=True, verbose=0)]\n",
    "        \n",
    "        model.fit(x = X_train, y= Y_train, validation_data=(X_valid, Y_valid),\n",
    "                  batch_size=batch_size,verbose=2, epochs=5, shuffle=True)\n",
    "        \n",
    "        K.set_value(model.optimizer.lr, 0.00001)\n",
    "        \n",
    "        model.fit(x = X_train, y= Y_train, validation_data=(X_valid, Y_valid),\n",
    "                  batch_size=batch_size, verbose=2, epochs=80, shuffle=True, callbacks = callbacks)\n",
    "        \n",
    "        \n",
    "        p_valid = model.predict(X_valid, batch_size = batch_size, verbose=2)\n",
    "        print(fbeta_score(Y_valid, np.array(p_valid) > 0.18, beta=2, average='samples'))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "import glob\n",
    "\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "\n",
    "PREDICTS_FILE = RESULT_DIR + '/preds'\n",
    "\n",
    "def ensemble():\n",
    "    preds = []\n",
    "    w_files = glob.glob(RESULT_DIR +'/wconv_*.h5')\n",
    "    for fn in w_files:\n",
    "        model = get_model()\n",
    "        print(fn)\n",
    "        model.load_weights(fn)\n",
    "        preds.append(model.predict(x_test, batch_size=128))\n",
    "    m = np.mean(preds, axis=0)\n",
    "    print(m.shape)\n",
    "    save_array(PREDICTS_FILE, m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = ensemble()\n",
    "\n",
    "result = pd.DataFrame(result, columns = labels)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "preds = []\n",
    "for i in tqdm(range(result.shape[0]), miniters=1000):\n",
    "    a = result.ix[[i]]\n",
    "    a = a.apply(lambda x: x > 0.18, axis=1)\n",
    "    a = a.transpose()\n",
    "    a = a.loc[a[i] == True]\n",
    "    ' '.join(list(a.index))\n",
    "    preds.append(' '.join(list(a.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test['tags'] = preds\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.to_csv(RESULT_DIR+'/v2_sub2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
