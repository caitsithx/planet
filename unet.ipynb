{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/chicm/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/chicm/data/planet'\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv(DATA_DIR+'/train.csv')\n",
    "df_test = pd.read_csv(DATA_DIR+'/sample_submission.csv')\n",
    "\n",
    "#flatten = lambda l:[item for sublist in l for item in sublist]\n",
    "labels = ['haze', 'cultivation', 'blooming', 'partly_cloudy', 'habitation', 'primary',\n",
    "            'road', 'agriculture', 'selective_logging', 'artisinal_mine', 'slash_burn',\n",
    "            'blow_down', 'cloudy', 'bare_ground', 'conventional_mine', 'clear', 'water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'haze', 1: 'cultivation', 2: 'blooming', 3: 'partly_cloudy', 4: 'habitation', 5: 'primary', 6: 'road', 7: 'agriculture', 8: 'selective_logging', 9: 'artisinal_mine', 10: 'slash_burn', 11: 'blow_down', 12: 'cloudy', 13: 'bare_ground', 14: 'conventional_mine', 15: 'clear', 16: 'water'}\n"
     ]
    }
   ],
   "source": [
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}\n",
    "print(inv_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:45<00:00, 892.77it/s]\n"
     ]
    }
   ],
   "source": [
    "for f, tags in tqdm(df_train.values, miniters=10000):\n",
    "    fn = DATA_DIR+'/train-jpg/'+f+'.jpg'\n",
    "    img = cv2.imread(fn) \n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1\n",
    "    x_train.append(cv2.resize(img, (64,64)))\n",
    "    y_train.append(targets)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40669/40669 [00:45<00:00, 892.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for f, tags in tqdm(df_test.values, miniters=10000):\n",
    "    fn = DATA_DIR+'/test-jpg/'+f+'.jpg'\n",
    "    img = cv2.imread(fn)\n",
    "    x_test.append(cv2.resize(img, (64, 64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(0,)\n",
      "(40669, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(x_train, np.float32) / 255.\n",
    "y_train = np.array(y_train, np.uint8)\n",
    "x_test = np.array(x_test, np.float32) / 255.\n",
    "print(x_train.shape) \n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers import Activation\n",
    "\n",
    "def get_unet():\n",
    "    inputs = Input((64, 64, 3))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='relu')(conv9)\n",
    "    result = Flatten()(conv10)\n",
    "    #result = Dense(256, activation='relu')(result)\n",
    "    result = Dense(17, activation='sigmoid')(result)\n",
    "    \n",
    "    #result = GlobalAveragePooling2D(activation='sigmoid')(conv10)\n",
    "    #result = Activation('sigmoid')\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=result)\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start KFold number 1 from 5\n",
      "Split train:  32383 32383\n",
      "Split valid:  8096 8096\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/10\n",
      "49s - loss: 0.2311 - acc: 0.9075 - val_loss: 0.1785 - val_acc: 0.9231\n",
      "Epoch 2/10\n",
      "48s - loss: 0.1663 - acc: 0.9321 - val_loss: 0.1608 - val_acc: 0.9353\n",
      "Epoch 3/10\n",
      "48s - loss: 0.1539 - acc: 0.9376 - val_loss: 0.1507 - val_acc: 0.9388\n",
      "Epoch 4/10\n",
      "48s - loss: 0.1448 - acc: 0.9411 - val_loss: 0.1478 - val_acc: 0.9396\n",
      "Epoch 5/10\n",
      "48s - loss: 0.1402 - acc: 0.9429 - val_loss: 0.1398 - val_acc: 0.9435\n",
      "Epoch 6/10\n",
      "48s - loss: 0.1353 - acc: 0.9451 - val_loss: 0.1323 - val_acc: 0.9464\n",
      "Epoch 7/10\n",
      "48s - loss: 0.1320 - acc: 0.9462 - val_loss: 0.1334 - val_acc: 0.9452\n",
      "Epoch 8/10\n",
      "48s - loss: 0.1289 - acc: 0.9475 - val_loss: 0.1308 - val_acc: 0.9474\n",
      "Epoch 9/10\n",
      "48s - loss: 0.1257 - acc: 0.9489 - val_loss: 0.1264 - val_acc: 0.9497\n",
      "Epoch 10/10\n",
      "47s - loss: 0.1233 - acc: 0.9500 - val_loss: 0.1300 - val_acc: 0.9477\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/50\n",
      "48s - loss: 0.1138 - acc: 0.9539 - val_loss: 0.1212 - val_acc: 0.9513\n",
      "Epoch 2/50\n",
      "47s - loss: 0.1112 - acc: 0.9551 - val_loss: 0.1206 - val_acc: 0.9518\n",
      "Epoch 3/50\n",
      "47s - loss: 0.1103 - acc: 0.9554 - val_loss: 0.1202 - val_acc: 0.9521\n",
      "Epoch 4/50\n",
      "47s - loss: 0.1097 - acc: 0.9556 - val_loss: 0.1200 - val_acc: 0.9522\n",
      "Epoch 5/50\n",
      "47s - loss: 0.1091 - acc: 0.9559 - val_loss: 0.1198 - val_acc: 0.9523\n",
      "Epoch 6/50\n",
      "47s - loss: 0.1086 - acc: 0.9560 - val_loss: 0.1197 - val_acc: 0.9525\n",
      "Epoch 7/50\n",
      "47s - loss: 0.1082 - acc: 0.9562 - val_loss: 0.1198 - val_acc: 0.9525\n",
      "Epoch 8/50\n",
      "47s - loss: 0.1078 - acc: 0.9564 - val_loss: 0.1196 - val_acc: 0.9523\n",
      "Epoch 9/50\n",
      "47s - loss: 0.1075 - acc: 0.9565 - val_loss: 0.1195 - val_acc: 0.9527\n",
      "Epoch 10/50\n",
      "47s - loss: 0.1072 - acc: 0.9567 - val_loss: 0.1194 - val_acc: 0.9524\n",
      "Epoch 11/50\n",
      "47s - loss: 0.1069 - acc: 0.9567 - val_loss: 0.1193 - val_acc: 0.9525\n",
      "Epoch 12/50\n",
      "47s - loss: 0.1066 - acc: 0.9569 - val_loss: 0.1193 - val_acc: 0.9527\n",
      "Epoch 13/50\n",
      "47s - loss: 0.1063 - acc: 0.9571 - val_loss: 0.1193 - val_acc: 0.9527\n",
      "Epoch 14/50\n",
      "47s - loss: 0.1060 - acc: 0.9572 - val_loss: 0.1193 - val_acc: 0.9524\n",
      "Epoch 15/50\n",
      "47s - loss: 0.1058 - acc: 0.9573 - val_loss: 0.1192 - val_acc: 0.9528\n",
      "Epoch 16/50\n",
      "48s - loss: 0.1055 - acc: 0.9573 - val_loss: 0.1191 - val_acc: 0.9526\n",
      "Epoch 17/50\n",
      "47s - loss: 0.1053 - acc: 0.9575 - val_loss: 0.1191 - val_acc: 0.9527\n",
      "Epoch 18/50\n",
      "47s - loss: 0.1050 - acc: 0.9576 - val_loss: 0.1192 - val_acc: 0.9526\n",
      "Epoch 19/50\n",
      "47s - loss: 0.1048 - acc: 0.9576 - val_loss: 0.1192 - val_acc: 0.9526\n",
      "Epoch 20/50\n",
      "47s - loss: 0.1046 - acc: 0.9577 - val_loss: 0.1191 - val_acc: 0.9526\n",
      "Epoch 21/50\n",
      "47s - loss: 0.1043 - acc: 0.9579 - val_loss: 0.1191 - val_acc: 0.9527\n",
      "Epoch 22/50\n",
      "47s - loss: 0.1041 - acc: 0.9579 - val_loss: 0.1191 - val_acc: 0.9528\n",
      "Epoch 23/50\n",
      "47s - loss: 0.1039 - acc: 0.9581 - val_loss: 0.1190 - val_acc: 0.9529\n",
      "Epoch 24/50\n",
      "47s - loss: 0.1036 - acc: 0.9581 - val_loss: 0.1192 - val_acc: 0.9528\n",
      "Epoch 25/50\n",
      "47s - loss: 0.1034 - acc: 0.9582 - val_loss: 0.1190 - val_acc: 0.9528\n",
      "Epoch 26/50\n",
      "47s - loss: 0.1032 - acc: 0.9584 - val_loss: 0.1190 - val_acc: 0.9530\n",
      "Epoch 27/50\n",
      "47s - loss: 0.1030 - acc: 0.9583 - val_loss: 0.1191 - val_acc: 0.9529\n",
      "Epoch 28/50\n",
      "47s - loss: 0.1028 - acc: 0.9585 - val_loss: 0.1192 - val_acc: 0.9530\n",
      "Epoch 29/50\n",
      "47s - loss: 0.1025 - acc: 0.9585 - val_loss: 0.1193 - val_acc: 0.9529\n",
      "Epoch 30/50\n",
      "47s - loss: 0.1023 - acc: 0.9586 - val_loss: 0.1192 - val_acc: 0.9528\n",
      "Epoch 31/50\n",
      "47s - loss: 0.1021 - acc: 0.9587 - val_loss: 0.1192 - val_acc: 0.9529\n",
      "Epoch 32/50\n",
      "47s - loss: 0.1019 - acc: 0.9588 - val_loss: 0.1193 - val_acc: 0.9528\n",
      "Epoch 33/50\n",
      "47s - loss: 0.1017 - acc: 0.9589 - val_loss: 0.1192 - val_acc: 0.9528\n",
      "Epoch 34/50\n",
      "47s - loss: 0.1016 - acc: 0.9590 - val_loss: 0.1192 - val_acc: 0.9530\n",
      "Epoch 35/50\n",
      "47s - loss: 0.1014 - acc: 0.9590 - val_loss: 0.1194 - val_acc: 0.9529\n",
      "Epoch 36/50\n",
      "47s - loss: 0.1011 - acc: 0.9592 - val_loss: 0.1193 - val_acc: 0.9530\n",
      "Epoch 37/50\n",
      "47s - loss: 0.1009 - acc: 0.9592 - val_loss: 0.1195 - val_acc: 0.9530\n",
      "Epoch 38/50\n",
      "47s - loss: 0.1007 - acc: 0.9592 - val_loss: 0.1195 - val_acc: 0.9529\n",
      "Epoch 39/50\n",
      "47s - loss: 0.1005 - acc: 0.9594 - val_loss: 0.1195 - val_acc: 0.9530\n",
      "Epoch 40/50\n",
      "47s - loss: 0.1003 - acc: 0.9594 - val_loss: 0.1197 - val_acc: 0.9529\n",
      "Epoch 41/50\n",
      "47s - loss: 0.1001 - acc: 0.9595 - val_loss: 0.1197 - val_acc: 0.9529\n",
      "Epoch 42/50\n",
      "47s - loss: 0.0999 - acc: 0.9596 - val_loss: 0.1196 - val_acc: 0.9530\n",
      "Epoch 43/50\n",
      "47s - loss: 0.0997 - acc: 0.9596 - val_loss: 0.1198 - val_acc: 0.9529\n",
      "Epoch 44/50\n",
      "47s - loss: 0.0996 - acc: 0.9597 - val_loss: 0.1200 - val_acc: 0.9529\n",
      "Epoch 45/50\n",
      "47s - loss: 0.0993 - acc: 0.9598 - val_loss: 0.1200 - val_acc: 0.9528\n",
      "Epoch 46/50\n",
      "47s - loss: 0.0992 - acc: 0.9599 - val_loss: 0.1200 - val_acc: 0.9530\n",
      "Start KFold number 2 from 5\n",
      "Split train:  32383 32383\n",
      "Split valid:  8096 8096\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/10\n",
      "49s - loss: 0.2279 - acc: 0.9078 - val_loss: 0.1924 - val_acc: 0.9183\n",
      "Epoch 2/10\n",
      "48s - loss: 0.1666 - acc: 0.9321 - val_loss: 0.1585 - val_acc: 0.9349\n",
      "Epoch 3/10\n",
      "48s - loss: 0.1555 - acc: 0.9367 - val_loss: 0.1504 - val_acc: 0.9389\n",
      "Epoch 4/10\n",
      "48s - loss: 0.1487 - acc: 0.9396 - val_loss: 0.1443 - val_acc: 0.9424\n",
      "Epoch 5/10\n",
      "48s - loss: 0.1438 - acc: 0.9413 - val_loss: 0.1421 - val_acc: 0.9429\n",
      "Epoch 6/10\n",
      "48s - loss: 0.1387 - acc: 0.9435 - val_loss: 0.1426 - val_acc: 0.9433\n",
      "Epoch 7/10\n",
      "48s - loss: 0.1342 - acc: 0.9456 - val_loss: 0.1391 - val_acc: 0.9433\n",
      "Epoch 8/10\n",
      "48s - loss: 0.1315 - acc: 0.9465 - val_loss: 0.1341 - val_acc: 0.9447\n",
      "Epoch 9/10\n",
      "48s - loss: 0.1295 - acc: 0.9476 - val_loss: 0.1470 - val_acc: 0.9420\n",
      "Epoch 10/10\n",
      "48s - loss: 0.1277 - acc: 0.9484 - val_loss: 0.1308 - val_acc: 0.9480\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/50\n",
      "48s - loss: 0.1204 - acc: 0.9517 - val_loss: 0.1251 - val_acc: 0.9495\n",
      "Epoch 2/50\n",
      "48s - loss: 0.1174 - acc: 0.9528 - val_loss: 0.1241 - val_acc: 0.9499\n",
      "Epoch 3/50\n",
      "48s - loss: 0.1162 - acc: 0.9532 - val_loss: 0.1237 - val_acc: 0.9502\n",
      "Epoch 4/50\n",
      "48s - loss: 0.1153 - acc: 0.9535 - val_loss: 0.1233 - val_acc: 0.9502\n",
      "Epoch 5/50\n",
      "48s - loss: 0.1146 - acc: 0.9538 - val_loss: 0.1230 - val_acc: 0.9505\n",
      "Epoch 6/50\n",
      "48s - loss: 0.1141 - acc: 0.9540 - val_loss: 0.1227 - val_acc: 0.9504\n",
      "Epoch 7/50\n",
      "48s - loss: 0.1136 - acc: 0.9542 - val_loss: 0.1226 - val_acc: 0.9507\n",
      "Epoch 8/50\n",
      "48s - loss: 0.1131 - acc: 0.9545 - val_loss: 0.1223 - val_acc: 0.9508\n",
      "Epoch 9/50\n",
      "48s - loss: 0.1128 - acc: 0.9546 - val_loss: 0.1223 - val_acc: 0.9509\n",
      "Epoch 10/50\n",
      "48s - loss: 0.1124 - acc: 0.9547 - val_loss: 0.1221 - val_acc: 0.9507\n",
      "Epoch 11/50\n",
      "48s - loss: 0.1121 - acc: 0.9549 - val_loss: 0.1221 - val_acc: 0.9512\n",
      "Epoch 12/50\n",
      "48s - loss: 0.1118 - acc: 0.9549 - val_loss: 0.1217 - val_acc: 0.9511\n",
      "Epoch 13/50\n",
      "48s - loss: 0.1115 - acc: 0.9549 - val_loss: 0.1216 - val_acc: 0.9513\n",
      "Epoch 14/50\n",
      "48s - loss: 0.1112 - acc: 0.9552 - val_loss: 0.1217 - val_acc: 0.9511\n",
      "Epoch 15/50\n",
      "48s - loss: 0.1109 - acc: 0.9553 - val_loss: 0.1215 - val_acc: 0.9513\n",
      "Epoch 16/50\n",
      "48s - loss: 0.1107 - acc: 0.9554 - val_loss: 0.1214 - val_acc: 0.9513\n",
      "Epoch 17/50\n",
      "48s - loss: 0.1104 - acc: 0.9556 - val_loss: 0.1214 - val_acc: 0.9514\n",
      "Epoch 18/50\n",
      "47s - loss: 0.1102 - acc: 0.9556 - val_loss: 0.1214 - val_acc: 0.9515\n",
      "Epoch 19/50\n",
      "48s - loss: 0.1100 - acc: 0.9556 - val_loss: 0.1213 - val_acc: 0.9516\n",
      "Epoch 20/50\n",
      "48s - loss: 0.1098 - acc: 0.9558 - val_loss: 0.1213 - val_acc: 0.9516\n",
      "Epoch 21/50\n",
      "48s - loss: 0.1096 - acc: 0.9559 - val_loss: 0.1214 - val_acc: 0.9515\n",
      "Epoch 22/50\n",
      "48s - loss: 0.1093 - acc: 0.9560 - val_loss: 0.1212 - val_acc: 0.9515\n",
      "Epoch 23/50\n",
      "48s - loss: 0.1091 - acc: 0.9560 - val_loss: 0.1213 - val_acc: 0.9516\n",
      "Epoch 24/50\n",
      "48s - loss: 0.1089 - acc: 0.9561 - val_loss: 0.1212 - val_acc: 0.9518\n",
      "Epoch 25/50\n",
      "48s - loss: 0.1087 - acc: 0.9562 - val_loss: 0.1212 - val_acc: 0.9518\n",
      "Epoch 26/50\n",
      "48s - loss: 0.1085 - acc: 0.9563 - val_loss: 0.1211 - val_acc: 0.9518\n",
      "Epoch 27/50\n",
      "48s - loss: 0.1083 - acc: 0.9564 - val_loss: 0.1211 - val_acc: 0.9516\n",
      "Epoch 28/50\n",
      "48s - loss: 0.1081 - acc: 0.9565 - val_loss: 0.1209 - val_acc: 0.9520\n",
      "Epoch 29/50\n",
      "48s - loss: 0.1079 - acc: 0.9566 - val_loss: 0.1210 - val_acc: 0.9519\n",
      "Epoch 30/50\n",
      "48s - loss: 0.1077 - acc: 0.9566 - val_loss: 0.1210 - val_acc: 0.9521\n",
      "Epoch 31/50\n",
      "48s - loss: 0.1075 - acc: 0.9566 - val_loss: 0.1209 - val_acc: 0.9520\n",
      "Epoch 32/50\n",
      "48s - loss: 0.1073 - acc: 0.9568 - val_loss: 0.1209 - val_acc: 0.9521\n",
      "Epoch 33/50\n",
      "48s - loss: 0.1071 - acc: 0.9569 - val_loss: 0.1209 - val_acc: 0.9520\n",
      "Epoch 34/50\n",
      "48s - loss: 0.1070 - acc: 0.9569 - val_loss: 0.1211 - val_acc: 0.9518\n",
      "Epoch 35/50\n",
      "48s - loss: 0.1068 - acc: 0.9571 - val_loss: 0.1209 - val_acc: 0.9519\n",
      "Epoch 36/50\n",
      "48s - loss: 0.1066 - acc: 0.9571 - val_loss: 0.1209 - val_acc: 0.9521\n",
      "Epoch 37/50\n",
      "48s - loss: 0.1064 - acc: 0.9572 - val_loss: 0.1210 - val_acc: 0.9521\n",
      "Epoch 38/50\n",
      "48s - loss: 0.1062 - acc: 0.9572 - val_loss: 0.1210 - val_acc: 0.9522\n",
      "Epoch 39/50\n",
      "49s - loss: 0.1060 - acc: 0.9573 - val_loss: 0.1210 - val_acc: 0.9520\n",
      "Epoch 40/50\n",
      "49s - loss: 0.1059 - acc: 0.9574 - val_loss: 0.1209 - val_acc: 0.9523\n",
      "Epoch 41/50\n",
      "49s - loss: 0.1056 - acc: 0.9575 - val_loss: 0.1210 - val_acc: 0.9523\n",
      "Epoch 42/50\n",
      "48s - loss: 0.1055 - acc: 0.9576 - val_loss: 0.1211 - val_acc: 0.9521\n",
      "Epoch 43/50\n",
      "48s - loss: 0.1053 - acc: 0.9577 - val_loss: 0.1211 - val_acc: 0.9521\n",
      "Epoch 44/50\n",
      "49s - loss: 0.1051 - acc: 0.9577 - val_loss: 0.1209 - val_acc: 0.9524\n",
      "Epoch 45/50\n",
      "49s - loss: 0.1049 - acc: 0.9578 - val_loss: 0.1210 - val_acc: 0.9523\n",
      "Epoch 46/50\n",
      "49s - loss: 0.1048 - acc: 0.9578 - val_loss: 0.1210 - val_acc: 0.9523\n",
      "Epoch 47/50\n",
      "48s - loss: 0.1046 - acc: 0.9580 - val_loss: 0.1210 - val_acc: 0.9524\n",
      "Epoch 48/50\n",
      "49s - loss: 0.1044 - acc: 0.9580 - val_loss: 0.1212 - val_acc: 0.9522\n",
      "Epoch 49/50\n",
      "48s - loss: 0.1042 - acc: 0.9581 - val_loss: 0.1211 - val_acc: 0.9523\n",
      "Epoch 50/50\n",
      "48s - loss: 0.1040 - acc: 0.9582 - val_loss: 0.1214 - val_acc: 0.9522\n",
      "Start KFold number 3 from 5\n",
      "Split train:  32383 32383\n",
      "Split valid:  8096 8096\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/10\n",
      "47s - loss: 0.6458 - acc: 0.9034 - val_loss: 0.6019 - val_acc: 0.9038\n",
      "Epoch 2/10\n",
      "45s - loss: 0.5643 - acc: 0.9055 - val_loss: 0.5306 - val_acc: 0.9038\n",
      "Epoch 3/10\n",
      "45s - loss: 0.5009 - acc: 0.9055 - val_loss: 0.4751 - val_acc: 0.9038\n",
      "Epoch 4/10\n",
      "45s - loss: 0.4516 - acc: 0.9055 - val_loss: 0.4320 - val_acc: 0.9038\n",
      "Epoch 5/10\n",
      "45s - loss: 0.4131 - acc: 0.9055 - val_loss: 0.3984 - val_acc: 0.9038\n",
      "Epoch 6/10\n",
      "45s - loss: 0.3829 - acc: 0.9055 - val_loss: 0.3719 - val_acc: 0.9038\n",
      "Epoch 7/10\n",
      "44s - loss: 0.3592 - acc: 0.9055 - val_loss: 0.3510 - val_acc: 0.9038\n",
      "Epoch 8/10\n",
      "45s - loss: 0.3403 - acc: 0.9055 - val_loss: 0.3344 - val_acc: 0.9038\n",
      "Epoch 9/10\n",
      "45s - loss: 0.3252 - acc: 0.9055 - val_loss: 0.3211 - val_acc: 0.9038\n",
      "Epoch 10/10\n",
      "45s - loss: 0.3131 - acc: 0.9055 - val_loss: 0.3103 - val_acc: 0.9038\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/50\n",
      "45s - loss: 0.3078 - acc: 0.9055 - val_loss: 0.3102 - val_acc: 0.9038\n",
      "Epoch 2/50\n",
      "45s - loss: 0.3076 - acc: 0.9055 - val_loss: 0.3101 - val_acc: 0.9038\n",
      "Epoch 3/50\n",
      "45s - loss: 0.3075 - acc: 0.9055 - val_loss: 0.3100 - val_acc: 0.9038\n",
      "Epoch 4/50\n",
      "45s - loss: 0.3074 - acc: 0.9055 - val_loss: 0.3099 - val_acc: 0.9038\n",
      "Epoch 5/50\n",
      "45s - loss: 0.3073 - acc: 0.9055 - val_loss: 0.3097 - val_acc: 0.9038\n",
      "Epoch 6/50\n",
      "45s - loss: 0.3071 - acc: 0.9055 - val_loss: 0.3096 - val_acc: 0.9038\n",
      "Epoch 7/50\n",
      "45s - loss: 0.3070 - acc: 0.9055 - val_loss: 0.3095 - val_acc: 0.9038\n",
      "Epoch 8/50\n",
      "46s - loss: 0.3068 - acc: 0.9055 - val_loss: 0.3093 - val_acc: 0.9038\n",
      "Epoch 9/50\n",
      "45s - loss: 0.3067 - acc: 0.9055 - val_loss: 0.3092 - val_acc: 0.9038\n",
      "Epoch 10/50\n",
      "45s - loss: 0.3065 - acc: 0.9055 - val_loss: 0.3090 - val_acc: 0.9038\n",
      "Epoch 11/50\n",
      "45s - loss: 0.3064 - acc: 0.9055 - val_loss: 0.3088 - val_acc: 0.9038\n",
      "Epoch 12/50\n",
      "45s - loss: 0.3062 - acc: 0.9055 - val_loss: 0.3087 - val_acc: 0.9038\n",
      "Epoch 13/50\n",
      "45s - loss: 0.3060 - acc: 0.9055 - val_loss: 0.3085 - val_acc: 0.9038\n",
      "Epoch 14/50\n",
      "45s - loss: 0.3059 - acc: 0.9055 - val_loss: 0.3083 - val_acc: 0.9038\n",
      "Epoch 15/50\n",
      "45s - loss: 0.3057 - acc: 0.9055 - val_loss: 0.3082 - val_acc: 0.9038\n",
      "Epoch 16/50\n",
      "45s - loss: 0.3055 - acc: 0.9055 - val_loss: 0.3080 - val_acc: 0.9038\n",
      "Epoch 17/50\n",
      "45s - loss: 0.3054 - acc: 0.9055 - val_loss: 0.3078 - val_acc: 0.9038\n",
      "Epoch 18/50\n",
      "45s - loss: 0.3052 - acc: 0.9055 - val_loss: 0.3077 - val_acc: 0.9038\n",
      "Epoch 19/50\n",
      "45s - loss: 0.3050 - acc: 0.9055 - val_loss: 0.3075 - val_acc: 0.9038\n",
      "Epoch 20/50\n",
      "45s - loss: 0.3049 - acc: 0.9055 - val_loss: 0.3073 - val_acc: 0.9038\n",
      "Epoch 21/50\n",
      "45s - loss: 0.3047 - acc: 0.9055 - val_loss: 0.3072 - val_acc: 0.9038\n",
      "Epoch 22/50\n",
      "45s - loss: 0.3045 - acc: 0.9055 - val_loss: 0.3070 - val_acc: 0.9038\n",
      "Epoch 23/50\n",
      "45s - loss: 0.3044 - acc: 0.9055 - val_loss: 0.3069 - val_acc: 0.9038\n",
      "Epoch 24/50\n",
      "45s - loss: 0.3042 - acc: 0.9055 - val_loss: 0.3067 - val_acc: 0.9038\n",
      "Epoch 25/50\n",
      "45s - loss: 0.3040 - acc: 0.9055 - val_loss: 0.3065 - val_acc: 0.9038\n",
      "Epoch 26/50\n",
      "45s - loss: 0.3039 - acc: 0.9055 - val_loss: 0.3064 - val_acc: 0.9038\n",
      "Epoch 27/50\n",
      "46s - loss: 0.3037 - acc: 0.9055 - val_loss: 0.3062 - val_acc: 0.9038\n",
      "Epoch 28/50\n",
      "45s - loss: 0.3035 - acc: 0.9055 - val_loss: 0.3060 - val_acc: 0.9038\n",
      "Epoch 29/50\n",
      "45s - loss: 0.3034 - acc: 0.9055 - val_loss: 0.3059 - val_acc: 0.9038\n",
      "Epoch 30/50\n",
      "45s - loss: 0.3032 - acc: 0.9055 - val_loss: 0.3057 - val_acc: 0.9038\n",
      "Epoch 31/50\n",
      "45s - loss: 0.3030 - acc: 0.9055 - val_loss: 0.3055 - val_acc: 0.9038\n",
      "Epoch 32/50\n",
      "45s - loss: 0.3029 - acc: 0.9055 - val_loss: 0.3054 - val_acc: 0.9038\n",
      "Epoch 33/50\n",
      "45s - loss: 0.3027 - acc: 0.9055 - val_loss: 0.3052 - val_acc: 0.9038\n",
      "Epoch 34/50\n",
      "45s - loss: 0.3025 - acc: 0.9055 - val_loss: 0.3051 - val_acc: 0.9038\n",
      "Epoch 35/50\n",
      "45s - loss: 0.3024 - acc: 0.9055 - val_loss: 0.3049 - val_acc: 0.9038\n",
      "Epoch 36/50\n",
      "45s - loss: 0.3022 - acc: 0.9055 - val_loss: 0.3047 - val_acc: 0.9038\n",
      "Epoch 37/50\n",
      "45s - loss: 0.3021 - acc: 0.9055 - val_loss: 0.3046 - val_acc: 0.9038\n",
      "Epoch 38/50\n",
      "45s - loss: 0.3019 - acc: 0.9055 - val_loss: 0.3044 - val_acc: 0.9038\n",
      "Epoch 39/50\n",
      "45s - loss: 0.3017 - acc: 0.9055 - val_loss: 0.3043 - val_acc: 0.9038\n",
      "Epoch 40/50\n",
      "45s - loss: 0.3016 - acc: 0.9055 - val_loss: 0.3041 - val_acc: 0.9038\n",
      "Epoch 41/50\n",
      "45s - loss: 0.3014 - acc: 0.9055 - val_loss: 0.3040 - val_acc: 0.9038\n",
      "Epoch 42/50\n",
      "45s - loss: 0.3013 - acc: 0.9055 - val_loss: 0.3038 - val_acc: 0.9038\n",
      "Epoch 43/50\n",
      "45s - loss: 0.3011 - acc: 0.9055 - val_loss: 0.3036 - val_acc: 0.9038\n",
      "Epoch 44/50\n",
      "45s - loss: 0.3009 - acc: 0.9055 - val_loss: 0.3035 - val_acc: 0.9038\n",
      "Epoch 45/50\n",
      "45s - loss: 0.3008 - acc: 0.9055 - val_loss: 0.3033 - val_acc: 0.9038\n",
      "Epoch 46/50\n",
      "45s - loss: 0.3006 - acc: 0.9055 - val_loss: 0.3032 - val_acc: 0.9038\n",
      "Epoch 47/50\n",
      "45s - loss: 0.3005 - acc: 0.9055 - val_loss: 0.3030 - val_acc: 0.9038\n",
      "Epoch 48/50\n",
      "45s - loss: 0.3003 - acc: 0.9055 - val_loss: 0.3029 - val_acc: 0.9038\n",
      "Epoch 49/50\n",
      "45s - loss: 0.3002 - acc: 0.9055 - val_loss: 0.3027 - val_acc: 0.9038\n",
      "Epoch 50/50\n",
      "45s - loss: 0.3000 - acc: 0.9055 - val_loss: 0.3026 - val_acc: 0.9038\n",
      "Start KFold number 4 from 5\n",
      "Split train:  32383 32383\n",
      "Split valid:  8096 8096\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/10\n",
      "50s - loss: 0.2484 - acc: 0.9037 - val_loss: 0.2213 - val_acc: 0.9115\n",
      "Epoch 2/10\n",
      "50s - loss: 0.1973 - acc: 0.9189 - val_loss: 0.1780 - val_acc: 0.9271\n",
      "Epoch 3/10\n",
      "50s - loss: 0.1659 - acc: 0.9328 - val_loss: 0.1675 - val_acc: 0.9335\n",
      "Epoch 4/10\n",
      "49s - loss: 0.1521 - acc: 0.9383 - val_loss: 0.1477 - val_acc: 0.9399\n",
      "Epoch 5/10\n",
      "49s - loss: 0.1438 - acc: 0.9419 - val_loss: 0.1407 - val_acc: 0.9424\n",
      "Epoch 6/10\n",
      "49s - loss: 0.1383 - acc: 0.9438 - val_loss: 0.1403 - val_acc: 0.9428\n",
      "Epoch 7/10\n",
      "49s - loss: 0.1341 - acc: 0.9456 - val_loss: 0.1368 - val_acc: 0.9441\n",
      "Epoch 8/10\n",
      "48s - loss: 0.1305 - acc: 0.9469 - val_loss: 0.1319 - val_acc: 0.9457\n",
      "Epoch 9/10\n",
      "49s - loss: 0.1270 - acc: 0.9486 - val_loss: 0.1293 - val_acc: 0.9479\n",
      "Epoch 10/10\n",
      "48s - loss: 0.1243 - acc: 0.9499 - val_loss: 0.1269 - val_acc: 0.9484\n",
      "Train on 32383 samples, validate on 8096 samples\n",
      "Epoch 1/50\n",
      "49s - loss: 0.1142 - acc: 0.9540 - val_loss: 0.1231 - val_acc: 0.9500\n",
      "Epoch 2/50\n",
      "49s - loss: 0.1122 - acc: 0.9548 - val_loss: 0.1226 - val_acc: 0.9508\n",
      "Epoch 3/50\n",
      "49s - loss: 0.1114 - acc: 0.9550 - val_loss: 0.1223 - val_acc: 0.9508\n",
      "Epoch 4/50\n",
      "48s - loss: 0.1108 - acc: 0.9553 - val_loss: 0.1220 - val_acc: 0.9510\n",
      "Epoch 5/50\n",
      "49s - loss: 0.1103 - acc: 0.9555 - val_loss: 0.1219 - val_acc: 0.9511\n",
      "Epoch 6/50\n",
      "49s - loss: 0.1098 - acc: 0.9556 - val_loss: 0.1220 - val_acc: 0.9510\n",
      "Epoch 7/50\n",
      "48s - loss: 0.1094 - acc: 0.9557 - val_loss: 0.1218 - val_acc: 0.9511\n",
      "Epoch 8/50\n",
      "48s - loss: 0.1090 - acc: 0.9559 - val_loss: 0.1218 - val_acc: 0.9510\n",
      "Epoch 9/50\n",
      "48s - loss: 0.1087 - acc: 0.9561 - val_loss: 0.1216 - val_acc: 0.9512\n",
      "Epoch 10/50\n",
      "49s - loss: 0.1083 - acc: 0.9562 - val_loss: 0.1218 - val_acc: 0.9511\n",
      "Epoch 11/50\n",
      "48s - loss: 0.1080 - acc: 0.9563 - val_loss: 0.1217 - val_acc: 0.9509\n",
      "Epoch 12/50\n",
      "48s - loss: 0.1077 - acc: 0.9564 - val_loss: 0.1216 - val_acc: 0.9511\n",
      "Epoch 13/50\n",
      "48s - loss: 0.1074 - acc: 0.9565 - val_loss: 0.1216 - val_acc: 0.9511\n",
      "Epoch 14/50\n",
      "49s - loss: 0.1071 - acc: 0.9567 - val_loss: 0.1216 - val_acc: 0.9510\n",
      "Epoch 15/50\n",
      "48s - loss: 0.1068 - acc: 0.9568 - val_loss: 0.1216 - val_acc: 0.9510\n",
      "Epoch 16/50\n",
      "49s - loss: 0.1065 - acc: 0.9568 - val_loss: 0.1216 - val_acc: 0.9512\n",
      "Epoch 17/50\n",
      "48s - loss: 0.1063 - acc: 0.9570 - val_loss: 0.1218 - val_acc: 0.9509\n",
      "Epoch 18/50\n",
      "48s - loss: 0.1060 - acc: 0.9571 - val_loss: 0.1215 - val_acc: 0.9512\n",
      "Epoch 19/50\n",
      "48s - loss: 0.1057 - acc: 0.9572 - val_loss: 0.1215 - val_acc: 0.9512\n",
      "Epoch 20/50\n",
      "49s - loss: 0.1055 - acc: 0.9573 - val_loss: 0.1215 - val_acc: 0.9512\n",
      "Epoch 21/50\n",
      "49s - loss: 0.1052 - acc: 0.9574 - val_loss: 0.1218 - val_acc: 0.9511\n",
      "Epoch 22/50\n",
      "48s - loss: 0.1050 - acc: 0.9576 - val_loss: 0.1217 - val_acc: 0.9511\n",
      "Epoch 23/50\n",
      "48s - loss: 0.1047 - acc: 0.9577 - val_loss: 0.1216 - val_acc: 0.9512\n",
      "Epoch 24/50\n",
      "48s - loss: 0.1045 - acc: 0.9577 - val_loss: 0.1216 - val_acc: 0.9513\n",
      "Epoch 25/50\n",
      "48s - loss: 0.1043 - acc: 0.9579 - val_loss: 0.1218 - val_acc: 0.9513\n",
      "Epoch 26/50\n",
      "48s - loss: 0.1040 - acc: 0.9580 - val_loss: 0.1217 - val_acc: 0.9513\n",
      "Epoch 27/50\n",
      "48s - loss: 0.1038 - acc: 0.9581 - val_loss: 0.1218 - val_acc: 0.9513\n",
      "Epoch 28/50\n",
      "48s - loss: 0.1036 - acc: 0.9582 - val_loss: 0.1219 - val_acc: 0.9513\n",
      "Epoch 29/50\n",
      "49s - loss: 0.1033 - acc: 0.9583 - val_loss: 0.1219 - val_acc: 0.9515\n",
      "Epoch 30/50\n",
      "49s - loss: 0.1031 - acc: 0.9585 - val_loss: 0.1218 - val_acc: 0.9512\n",
      "Epoch 31/50\n",
      "49s - loss: 0.1029 - acc: 0.9585 - val_loss: 0.1220 - val_acc: 0.9512\n",
      "Epoch 32/50\n",
      "48s - loss: 0.1026 - acc: 0.9587 - val_loss: 0.1220 - val_acc: 0.9513\n",
      "Epoch 33/50\n",
      "49s - loss: 0.1024 - acc: 0.9587 - val_loss: 0.1221 - val_acc: 0.9513\n",
      "Epoch 34/50\n",
      "48s - loss: 0.1022 - acc: 0.9588 - val_loss: 0.1220 - val_acc: 0.9513\n",
      "Epoch 35/50\n",
      "48s - loss: 0.1020 - acc: 0.9589 - val_loss: 0.1223 - val_acc: 0.9512\n",
      "Epoch 36/50\n",
      "49s - loss: 0.1018 - acc: 0.9590 - val_loss: 0.1222 - val_acc: 0.9513\n",
      "Epoch 37/50\n",
      "48s - loss: 0.1015 - acc: 0.9591 - val_loss: 0.1220 - val_acc: 0.9513\n",
      "Epoch 38/50\n",
      "48s - loss: 0.1013 - acc: 0.9592 - val_loss: 0.1223 - val_acc: 0.9514\n",
      "Epoch 39/50\n",
      "48s - loss: 0.1011 - acc: 0.9593 - val_loss: 0.1223 - val_acc: 0.9511\n",
      "Epoch 40/50\n",
      "48s - loss: 0.1009 - acc: 0.9594 - val_loss: 0.1224 - val_acc: 0.9514\n",
      "Epoch 41/50\n",
      "48s - loss: 0.1007 - acc: 0.9596 - val_loss: 0.1224 - val_acc: 0.9514\n",
      "Start KFold number 5 from 5\n",
      "Split train:  32384 32384\n",
      "Split valid:  8095 8095\n",
      "Train on 32384 samples, validate on 8095 samples\n",
      "Epoch 1/10\n",
      "51s - loss: 0.2510 - acc: 0.9034 - val_loss: 0.2022 - val_acc: 0.9188\n",
      "Epoch 2/10\n",
      "49s - loss: 0.1755 - acc: 0.9288 - val_loss: 0.1563 - val_acc: 0.9364\n",
      "Epoch 3/10\n",
      "49s - loss: 0.1537 - acc: 0.9377 - val_loss: 0.1478 - val_acc: 0.9399\n",
      "Epoch 4/10\n",
      "49s - loss: 0.1453 - acc: 0.9410 - val_loss: 0.1400 - val_acc: 0.9424\n",
      "Epoch 5/10\n",
      "49s - loss: 0.1390 - acc: 0.9435 - val_loss: 0.1370 - val_acc: 0.9440\n",
      "Epoch 6/10\n",
      "49s - loss: 0.1357 - acc: 0.9448 - val_loss: 0.1285 - val_acc: 0.9479\n",
      "Epoch 7/10\n",
      "49s - loss: 0.1291 - acc: 0.9478 - val_loss: 0.1280 - val_acc: 0.9483\n",
      "Epoch 8/10\n",
      "49s - loss: 0.1251 - acc: 0.9495 - val_loss: 0.1265 - val_acc: 0.9491\n",
      "Epoch 9/10\n",
      "49s - loss: 0.1229 - acc: 0.9505 - val_loss: 0.1268 - val_acc: 0.9493\n",
      "Epoch 10/10\n",
      "49s - loss: 0.1203 - acc: 0.9518 - val_loss: 0.1252 - val_acc: 0.9491\n",
      "Train on 32384 samples, validate on 8095 samples\n",
      "Epoch 1/50\n",
      "50s - loss: 0.1119 - acc: 0.9552 - val_loss: 0.1182 - val_acc: 0.9529\n",
      "Epoch 2/50\n",
      "49s - loss: 0.1096 - acc: 0.9562 - val_loss: 0.1175 - val_acc: 0.9532\n",
      "Epoch 3/50\n",
      "49s - loss: 0.1087 - acc: 0.9566 - val_loss: 0.1171 - val_acc: 0.9533\n",
      "Epoch 4/50\n",
      "49s - loss: 0.1081 - acc: 0.9568 - val_loss: 0.1167 - val_acc: 0.9533\n",
      "Epoch 5/50\n",
      "49s - loss: 0.1077 - acc: 0.9570 - val_loss: 0.1165 - val_acc: 0.9535\n",
      "Epoch 6/50\n",
      "49s - loss: 0.1073 - acc: 0.9570 - val_loss: 0.1164 - val_acc: 0.9536\n",
      "Epoch 7/50\n",
      "49s - loss: 0.1069 - acc: 0.9572 - val_loss: 0.1162 - val_acc: 0.9535\n",
      "Epoch 8/50\n",
      "49s - loss: 0.1066 - acc: 0.9574 - val_loss: 0.1160 - val_acc: 0.9535\n",
      "Epoch 9/50\n",
      "49s - loss: 0.1063 - acc: 0.9575 - val_loss: 0.1160 - val_acc: 0.9537\n",
      "Epoch 10/50\n",
      "49s - loss: 0.1060 - acc: 0.9576 - val_loss: 0.1162 - val_acc: 0.9536\n",
      "Epoch 11/50\n",
      "49s - loss: 0.1058 - acc: 0.9577 - val_loss: 0.1158 - val_acc: 0.9538\n",
      "Epoch 12/50\n",
      "49s - loss: 0.1055 - acc: 0.9578 - val_loss: 0.1158 - val_acc: 0.9537\n",
      "Epoch 13/50\n",
      "49s - loss: 0.1053 - acc: 0.9578 - val_loss: 0.1158 - val_acc: 0.9538\n",
      "Epoch 14/50\n",
      "49s - loss: 0.1051 - acc: 0.9580 - val_loss: 0.1157 - val_acc: 0.9537\n",
      "Epoch 15/50\n",
      "49s - loss: 0.1048 - acc: 0.9581 - val_loss: 0.1158 - val_acc: 0.9538\n",
      "Epoch 16/50\n",
      "49s - loss: 0.1046 - acc: 0.9581 - val_loss: 0.1156 - val_acc: 0.9538\n",
      "Epoch 17/50\n",
      "49s - loss: 0.1044 - acc: 0.9583 - val_loss: 0.1156 - val_acc: 0.9539\n",
      "Epoch 18/50\n",
      "49s - loss: 0.1042 - acc: 0.9584 - val_loss: 0.1155 - val_acc: 0.9539\n",
      "Epoch 19/50\n",
      "49s - loss: 0.1040 - acc: 0.9584 - val_loss: 0.1155 - val_acc: 0.9541\n",
      "Epoch 20/50\n",
      "49s - loss: 0.1037 - acc: 0.9585 - val_loss: 0.1157 - val_acc: 0.9540\n",
      "Epoch 21/50\n",
      "49s - loss: 0.1036 - acc: 0.9586 - val_loss: 0.1155 - val_acc: 0.9538\n",
      "Epoch 22/50\n",
      "49s - loss: 0.1034 - acc: 0.9587 - val_loss: 0.1156 - val_acc: 0.9539\n",
      "Epoch 23/50\n",
      "49s - loss: 0.1032 - acc: 0.9589 - val_loss: 0.1156 - val_acc: 0.9540\n",
      "Epoch 24/50\n",
      "49s - loss: 0.1030 - acc: 0.9588 - val_loss: 0.1155 - val_acc: 0.9538\n",
      "Epoch 25/50\n",
      "49s - loss: 0.1029 - acc: 0.9589 - val_loss: 0.1154 - val_acc: 0.9540\n",
      "Epoch 26/50\n",
      "49s - loss: 0.1027 - acc: 0.9590 - val_loss: 0.1155 - val_acc: 0.9539\n",
      "Epoch 27/50\n",
      "49s - loss: 0.1025 - acc: 0.9589 - val_loss: 0.1154 - val_acc: 0.9541\n",
      "Epoch 28/50\n",
      "49s - loss: 0.1023 - acc: 0.9592 - val_loss: 0.1155 - val_acc: 0.9540\n",
      "Epoch 29/50\n",
      "49s - loss: 0.1021 - acc: 0.9592 - val_loss: 0.1155 - val_acc: 0.9540\n",
      "Epoch 30/50\n",
      "49s - loss: 0.1019 - acc: 0.9593 - val_loss: 0.1153 - val_acc: 0.9541\n",
      "Epoch 31/50\n",
      "49s - loss: 0.1018 - acc: 0.9594 - val_loss: 0.1155 - val_acc: 0.9540\n",
      "Epoch 32/50\n",
      "49s - loss: 0.1016 - acc: 0.9595 - val_loss: 0.1156 - val_acc: 0.9540\n",
      "Epoch 33/50\n",
      "49s - loss: 0.1014 - acc: 0.9595 - val_loss: 0.1157 - val_acc: 0.9541\n",
      "Epoch 34/50\n",
      "49s - loss: 0.1013 - acc: 0.9595 - val_loss: 0.1155 - val_acc: 0.9540\n",
      "Epoch 35/50\n",
      "49s - loss: 0.1011 - acc: 0.9596 - val_loss: 0.1153 - val_acc: 0.9538\n",
      "Epoch 36/50\n",
      "49s - loss: 0.1009 - acc: 0.9597 - val_loss: 0.1155 - val_acc: 0.9540\n",
      "Epoch 37/50\n",
      "49s - loss: 0.1007 - acc: 0.9598 - val_loss: 0.1156 - val_acc: 0.9541\n",
      "Epoch 38/50\n",
      "49s - loss: 0.1006 - acc: 0.9598 - val_loss: 0.1156 - val_acc: 0.9541\n",
      "Epoch 39/50\n",
      "49s - loss: 0.1004 - acc: 0.9599 - val_loss: 0.1156 - val_acc: 0.9539\n",
      "Epoch 40/50\n",
      "49s - loss: 0.1002 - acc: 0.9599 - val_loss: 0.1157 - val_acc: 0.9541\n",
      "Epoch 41/50\n",
      "49s - loss: 0.1000 - acc: 0.9600 - val_loss: 0.1155 - val_acc: 0.9539\n",
      "Epoch 42/50\n",
      "49s - loss: 0.0999 - acc: 0.9601 - val_loss: 0.1156 - val_acc: 0.9543\n",
      "Epoch 43/50\n",
      "49s - loss: 0.0997 - acc: 0.9601 - val_loss: 0.1155 - val_acc: 0.9541\n",
      "Epoch 44/50\n",
      "49s - loss: 0.0995 - acc: 0.9602 - val_loss: 0.1155 - val_acc: 0.9542\n",
      "Epoch 45/50\n",
      "49s - loss: 0.0994 - acc: 0.9603 - val_loss: 0.1157 - val_acc: 0.9540\n",
      "Epoch 46/50\n",
      "49s - loss: 0.0992 - acc: 0.9603 - val_loss: 0.1159 - val_acc: 0.9541\n",
      "Epoch 47/50\n",
      "49s - loss: 0.0990 - acc: 0.9605 - val_loss: 0.1159 - val_acc: 0.9541\n",
      "Epoch 48/50\n",
      "49s - loss: 0.0988 - acc: 0.9604 - val_loss: 0.1160 - val_acc: 0.9542\n",
      "Epoch 49/50\n",
      "49s - loss: 0.0987 - acc: 0.9605 - val_loss: 0.1157 - val_acc: 0.9543\n",
      "Epoch 50/50\n",
      "49s - loss: 0.0985 - acc: 0.9606 - val_loss: 0.1159 - val_acc: 0.9543\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "RESULT_DIR = DATA_DIR +'/results'\n",
    "nfolds = 5\n",
    "batch_size = 128\n",
    "\n",
    "num_fold = 0\n",
    "sum_score = 0\n",
    "\n",
    "yfull_test = []\n",
    "yfull_train =[]\n",
    "\n",
    "kf = KFold(len(y_train), n_folds=nfolds, shuffle=True, random_state=1)\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "        start_time_model_fitting = time.time()\n",
    "        \n",
    "        X_train = x_train[train_index]\n",
    "        Y_train = y_train[train_index]\n",
    "        X_valid = x_train[test_index]\n",
    "        Y_valid = y_train[test_index]\n",
    "\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        print('Split train: ', len(X_train), len(Y_train))\n",
    "        print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "        \n",
    "        kfold_weights_path = RESULT_DIR +'/w_unet_' + str(num_fold) + '.h5'\n",
    "        \n",
    "        model = get_unet()\n",
    "        model.fit(x = X_train, y= Y_train, validation_data=(X_valid, Y_valid),\n",
    "                  batch_size=batch_size, epochs=10, verbose=2)\n",
    "        \n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=20, verbose=0),\n",
    "            ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0)]\n",
    "        \n",
    "        K.set_value(model.optimizer.lr, 0.00001)\n",
    "        model.fit(x = X_train, y= Y_train, validation_data=(X_valid, Y_valid),\n",
    "                  batch_size=batch_size, epochs=50,callbacks=callbacks, verbose=2)\n",
    "        \n",
    "        \n",
    "        #if os.path.isfile(kfold_weights_path):\n",
    "        #    model.load_weights(kfold_weights_path)\n",
    "        \n",
    "        #p_valid = model.predict(X_valid, batch_size = batch_size, verbose=2)\n",
    "        #print(fbeta_score(Y_valid, np.array(p_valid) > 0.15, beta=2, average='samples'))\n",
    "        \n",
    "        #p_test = model.predict(x_train, batch_size = batch_size, verbose=2)\n",
    "        #yfull_train.append(p_test)\n",
    "        \n",
    "        #p_test = model.predict(x_test, batch_size = batch_size, verbose=2)\n",
    "        #yfull_test.append(p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "import glob\n",
    "\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "\n",
    "RESULT_DIR = DATA_DIR + '/results'\n",
    "PREDICTS_FILE = RESULT_DIR + '/preds_unet'\n",
    "\n",
    "def ensemble():\n",
    "    preds = []\n",
    "    w_files = glob.glob(RESULT_DIR +'/w_unet_*.h5')\n",
    "    for fn in w_files:\n",
    "        model = get_unet()\n",
    "        print(fn)\n",
    "        model.load_weights(fn)\n",
    "        preds.append(model.predict(x_test, batch_size=128))\n",
    "    m = np.mean(preds, axis=0)\n",
    "    print(m.shape)\n",
    "    save_array(PREDICTS_FILE, m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chicm/data/planet/results/w_unet_2.h5\n",
      "/home/chicm/data/planet/results/w_unet_4.h5\n",
      "/home/chicm/data/planet/results/w_unet_3.h5\n",
      "/home/chicm/data/planet/results/w_unet_5.h5\n",
      "/home/chicm/data/planet/results/w_unet_1.h5\n",
      "(40669, 17)\n"
     ]
    }
   ],
   "source": [
    "result = ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02869967  0.03061962  0.03616161  0.03835546  0.02895715  0.97363645\n",
      "   0.04487121  0.06509243  0.02450787  0.0235552   0.02343875  0.02384736\n",
      "   0.02583506  0.02438288  0.02332936  0.93729609  0.04892532]\n",
      " [ 0.02693769  0.0521944   0.04016238  0.0408045   0.03084663  0.97363508\n",
      "   0.0646693   0.10611455  0.03913807  0.02358452  0.02372024  0.03400344\n",
      "   0.02585673  0.02559867  0.02337409  0.93529862  0.12509288]]\n"
     ]
    }
   ],
   "source": [
    "print(result[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>haze</th>\n",
       "      <th>cultivation</th>\n",
       "      <th>blooming</th>\n",
       "      <th>partly_cloudy</th>\n",
       "      <th>habitation</th>\n",
       "      <th>primary</th>\n",
       "      <th>road</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>selective_logging</th>\n",
       "      <th>artisinal_mine</th>\n",
       "      <th>slash_burn</th>\n",
       "      <th>blow_down</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>bare_ground</th>\n",
       "      <th>conventional_mine</th>\n",
       "      <th>clear</th>\n",
       "      <th>water</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.030620</td>\n",
       "      <td>0.036162</td>\n",
       "      <td>0.038355</td>\n",
       "      <td>0.028957</td>\n",
       "      <td>0.973636</td>\n",
       "      <td>0.044871</td>\n",
       "      <td>0.065092</td>\n",
       "      <td>0.024508</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.023439</td>\n",
       "      <td>0.023847</td>\n",
       "      <td>0.025835</td>\n",
       "      <td>0.024383</td>\n",
       "      <td>0.023329</td>\n",
       "      <td>0.937296</td>\n",
       "      <td>0.048925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026938</td>\n",
       "      <td>0.052194</td>\n",
       "      <td>0.040162</td>\n",
       "      <td>0.040805</td>\n",
       "      <td>0.030847</td>\n",
       "      <td>0.973635</td>\n",
       "      <td>0.064669</td>\n",
       "      <td>0.106115</td>\n",
       "      <td>0.039138</td>\n",
       "      <td>0.023585</td>\n",
       "      <td>0.023720</td>\n",
       "      <td>0.034003</td>\n",
       "      <td>0.025857</td>\n",
       "      <td>0.025599</td>\n",
       "      <td>0.023374</td>\n",
       "      <td>0.935299</td>\n",
       "      <td>0.125093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026471</td>\n",
       "      <td>0.063229</td>\n",
       "      <td>0.024015</td>\n",
       "      <td>0.836597</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.972833</td>\n",
       "      <td>0.073065</td>\n",
       "      <td>0.128349</td>\n",
       "      <td>0.024471</td>\n",
       "      <td>0.023968</td>\n",
       "      <td>0.024879</td>\n",
       "      <td>0.024058</td>\n",
       "      <td>0.026394</td>\n",
       "      <td>0.025432</td>\n",
       "      <td>0.023435</td>\n",
       "      <td>0.139797</td>\n",
       "      <td>0.130319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031146</td>\n",
       "      <td>0.348414</td>\n",
       "      <td>0.037752</td>\n",
       "      <td>0.041573</td>\n",
       "      <td>0.037574</td>\n",
       "      <td>0.973624</td>\n",
       "      <td>0.060415</td>\n",
       "      <td>0.317086</td>\n",
       "      <td>0.031035</td>\n",
       "      <td>0.023622</td>\n",
       "      <td>0.032051</td>\n",
       "      <td>0.030560</td>\n",
       "      <td>0.025854</td>\n",
       "      <td>0.034290</td>\n",
       "      <td>0.023419</td>\n",
       "      <td>0.932555</td>\n",
       "      <td>0.110725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027897</td>\n",
       "      <td>0.043863</td>\n",
       "      <td>0.023641</td>\n",
       "      <td>0.625688</td>\n",
       "      <td>0.036407</td>\n",
       "      <td>0.822585</td>\n",
       "      <td>0.096402</td>\n",
       "      <td>0.154245</td>\n",
       "      <td>0.023595</td>\n",
       "      <td>0.023720</td>\n",
       "      <td>0.023486</td>\n",
       "      <td>0.023383</td>\n",
       "      <td>0.269760</td>\n",
       "      <td>0.028236</td>\n",
       "      <td>0.023494</td>\n",
       "      <td>0.139999</td>\n",
       "      <td>0.144990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.026563</td>\n",
       "      <td>0.030426</td>\n",
       "      <td>0.030768</td>\n",
       "      <td>0.038251</td>\n",
       "      <td>0.028648</td>\n",
       "      <td>0.973687</td>\n",
       "      <td>0.046380</td>\n",
       "      <td>0.065224</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.023432</td>\n",
       "      <td>0.023834</td>\n",
       "      <td>0.025831</td>\n",
       "      <td>0.024158</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>0.939171</td>\n",
       "      <td>0.049384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.057428</td>\n",
       "      <td>0.355900</td>\n",
       "      <td>0.025466</td>\n",
       "      <td>0.265411</td>\n",
       "      <td>0.107987</td>\n",
       "      <td>0.972856</td>\n",
       "      <td>0.201706</td>\n",
       "      <td>0.642872</td>\n",
       "      <td>0.027171</td>\n",
       "      <td>0.024039</td>\n",
       "      <td>0.041086</td>\n",
       "      <td>0.026417</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.023888</td>\n",
       "      <td>0.503907</td>\n",
       "      <td>0.218843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.030707</td>\n",
       "      <td>0.036791</td>\n",
       "      <td>0.023561</td>\n",
       "      <td>0.040037</td>\n",
       "      <td>0.763600</td>\n",
       "      <td>0.790682</td>\n",
       "      <td>0.818932</td>\n",
       "      <td>0.270763</td>\n",
       "      <td>0.024248</td>\n",
       "      <td>0.048928</td>\n",
       "      <td>0.023457</td>\n",
       "      <td>0.023327</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>0.060152</td>\n",
       "      <td>0.035618</td>\n",
       "      <td>0.930863</td>\n",
       "      <td>0.173067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.026597</td>\n",
       "      <td>0.030199</td>\n",
       "      <td>0.027406</td>\n",
       "      <td>0.038283</td>\n",
       "      <td>0.028414</td>\n",
       "      <td>0.973676</td>\n",
       "      <td>0.043991</td>\n",
       "      <td>0.064822</td>\n",
       "      <td>0.023731</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>0.023494</td>\n",
       "      <td>0.025827</td>\n",
       "      <td>0.024164</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>0.939115</td>\n",
       "      <td>0.044568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.726279</td>\n",
       "      <td>0.141329</td>\n",
       "      <td>0.024536</td>\n",
       "      <td>0.048267</td>\n",
       "      <td>0.044932</td>\n",
       "      <td>0.972255</td>\n",
       "      <td>0.164649</td>\n",
       "      <td>0.409359</td>\n",
       "      <td>0.024145</td>\n",
       "      <td>0.023572</td>\n",
       "      <td>0.024541</td>\n",
       "      <td>0.023517</td>\n",
       "      <td>0.026720</td>\n",
       "      <td>0.028662</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>0.309497</td>\n",
       "      <td>0.298286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.026513</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.024441</td>\n",
       "      <td>0.837893</td>\n",
       "      <td>0.041098</td>\n",
       "      <td>0.973510</td>\n",
       "      <td>0.126887</td>\n",
       "      <td>0.271982</td>\n",
       "      <td>0.025435</td>\n",
       "      <td>0.023867</td>\n",
       "      <td>0.026314</td>\n",
       "      <td>0.025624</td>\n",
       "      <td>0.025849</td>\n",
       "      <td>0.026873</td>\n",
       "      <td>0.023519</td>\n",
       "      <td>0.139528</td>\n",
       "      <td>0.155376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.026822</td>\n",
       "      <td>0.627410</td>\n",
       "      <td>0.028353</td>\n",
       "      <td>0.040099</td>\n",
       "      <td>0.186354</td>\n",
       "      <td>0.973677</td>\n",
       "      <td>0.172807</td>\n",
       "      <td>0.632966</td>\n",
       "      <td>0.052170</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>0.070224</td>\n",
       "      <td>0.029096</td>\n",
       "      <td>0.025826</td>\n",
       "      <td>0.045982</td>\n",
       "      <td>0.024104</td>\n",
       "      <td>0.936886</td>\n",
       "      <td>0.199267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.095917</td>\n",
       "      <td>0.030959</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.059999</td>\n",
       "      <td>0.029409</td>\n",
       "      <td>0.266209</td>\n",
       "      <td>0.056645</td>\n",
       "      <td>0.073978</td>\n",
       "      <td>0.023554</td>\n",
       "      <td>0.023559</td>\n",
       "      <td>0.023429</td>\n",
       "      <td>0.023323</td>\n",
       "      <td>0.785729</td>\n",
       "      <td>0.024198</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.140228</td>\n",
       "      <td>0.076852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.027575</td>\n",
       "      <td>0.489600</td>\n",
       "      <td>0.031541</td>\n",
       "      <td>0.041004</td>\n",
       "      <td>0.114407</td>\n",
       "      <td>0.973496</td>\n",
       "      <td>0.172647</td>\n",
       "      <td>0.576776</td>\n",
       "      <td>0.043732</td>\n",
       "      <td>0.024288</td>\n",
       "      <td>0.041507</td>\n",
       "      <td>0.028966</td>\n",
       "      <td>0.025829</td>\n",
       "      <td>0.043799</td>\n",
       "      <td>0.023892</td>\n",
       "      <td>0.935993</td>\n",
       "      <td>0.154409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.176140</td>\n",
       "      <td>0.239627</td>\n",
       "      <td>0.028866</td>\n",
       "      <td>0.050856</td>\n",
       "      <td>0.042147</td>\n",
       "      <td>0.973131</td>\n",
       "      <td>0.079520</td>\n",
       "      <td>0.376316</td>\n",
       "      <td>0.027081</td>\n",
       "      <td>0.023679</td>\n",
       "      <td>0.027723</td>\n",
       "      <td>0.024544</td>\n",
       "      <td>0.026030</td>\n",
       "      <td>0.041079</td>\n",
       "      <td>0.023481</td>\n",
       "      <td>0.802677</td>\n",
       "      <td>0.222147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.026547</td>\n",
       "      <td>0.038334</td>\n",
       "      <td>0.052213</td>\n",
       "      <td>0.038435</td>\n",
       "      <td>0.029978</td>\n",
       "      <td>0.973650</td>\n",
       "      <td>0.067910</td>\n",
       "      <td>0.099070</td>\n",
       "      <td>0.032017</td>\n",
       "      <td>0.023559</td>\n",
       "      <td>0.023722</td>\n",
       "      <td>0.029002</td>\n",
       "      <td>0.025834</td>\n",
       "      <td>0.025654</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>0.938993</td>\n",
       "      <td>0.081904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.026997</td>\n",
       "      <td>0.261919</td>\n",
       "      <td>0.024909</td>\n",
       "      <td>0.039278</td>\n",
       "      <td>0.538030</td>\n",
       "      <td>0.973099</td>\n",
       "      <td>0.588097</td>\n",
       "      <td>0.804455</td>\n",
       "      <td>0.037558</td>\n",
       "      <td>0.024229</td>\n",
       "      <td>0.067406</td>\n",
       "      <td>0.030308</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>0.052378</td>\n",
       "      <td>0.024861</td>\n",
       "      <td>0.937726</td>\n",
       "      <td>0.099728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.028742</td>\n",
       "      <td>0.044362</td>\n",
       "      <td>0.034703</td>\n",
       "      <td>0.762553</td>\n",
       "      <td>0.031924</td>\n",
       "      <td>0.972069</td>\n",
       "      <td>0.045929</td>\n",
       "      <td>0.084060</td>\n",
       "      <td>0.024943</td>\n",
       "      <td>0.023584</td>\n",
       "      <td>0.023852</td>\n",
       "      <td>0.027657</td>\n",
       "      <td>0.026415</td>\n",
       "      <td>0.025989</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>0.302940</td>\n",
       "      <td>0.057746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.128331</td>\n",
       "      <td>0.032971</td>\n",
       "      <td>0.026587</td>\n",
       "      <td>0.040645</td>\n",
       "      <td>0.028764</td>\n",
       "      <td>0.973321</td>\n",
       "      <td>0.050932</td>\n",
       "      <td>0.075084</td>\n",
       "      <td>0.023789</td>\n",
       "      <td>0.023559</td>\n",
       "      <td>0.023444</td>\n",
       "      <td>0.023470</td>\n",
       "      <td>0.026166</td>\n",
       "      <td>0.025186</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>0.826794</td>\n",
       "      <td>0.121737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.026732</td>\n",
       "      <td>0.064501</td>\n",
       "      <td>0.036798</td>\n",
       "      <td>0.038383</td>\n",
       "      <td>0.073407</td>\n",
       "      <td>0.973491</td>\n",
       "      <td>0.568266</td>\n",
       "      <td>0.172875</td>\n",
       "      <td>0.165742</td>\n",
       "      <td>0.030820</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.027605</td>\n",
       "      <td>0.025830</td>\n",
       "      <td>0.028078</td>\n",
       "      <td>0.024864</td>\n",
       "      <td>0.938903</td>\n",
       "      <td>0.601366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.026673</td>\n",
       "      <td>0.080784</td>\n",
       "      <td>0.025852</td>\n",
       "      <td>0.038353</td>\n",
       "      <td>0.083301</td>\n",
       "      <td>0.973598</td>\n",
       "      <td>0.384998</td>\n",
       "      <td>0.225124</td>\n",
       "      <td>0.060468</td>\n",
       "      <td>0.036986</td>\n",
       "      <td>0.025090</td>\n",
       "      <td>0.025555</td>\n",
       "      <td>0.025831</td>\n",
       "      <td>0.043263</td>\n",
       "      <td>0.028474</td>\n",
       "      <td>0.938962</td>\n",
       "      <td>0.649110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.047460</td>\n",
       "      <td>0.053717</td>\n",
       "      <td>0.023617</td>\n",
       "      <td>0.039255</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>0.918591</td>\n",
       "      <td>0.234642</td>\n",
       "      <td>0.410502</td>\n",
       "      <td>0.023742</td>\n",
       "      <td>0.025508</td>\n",
       "      <td>0.023522</td>\n",
       "      <td>0.023332</td>\n",
       "      <td>0.042833</td>\n",
       "      <td>0.049230</td>\n",
       "      <td>0.024880</td>\n",
       "      <td>0.896248</td>\n",
       "      <td>0.711910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.050006</td>\n",
       "      <td>0.228246</td>\n",
       "      <td>0.023652</td>\n",
       "      <td>0.132060</td>\n",
       "      <td>0.367833</td>\n",
       "      <td>0.965097</td>\n",
       "      <td>0.661998</td>\n",
       "      <td>0.820809</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>0.024086</td>\n",
       "      <td>0.029850</td>\n",
       "      <td>0.023568</td>\n",
       "      <td>0.025881</td>\n",
       "      <td>0.041679</td>\n",
       "      <td>0.024731</td>\n",
       "      <td>0.755792</td>\n",
       "      <td>0.135235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.124646</td>\n",
       "      <td>0.031074</td>\n",
       "      <td>0.023556</td>\n",
       "      <td>0.039011</td>\n",
       "      <td>0.028769</td>\n",
       "      <td>0.262284</td>\n",
       "      <td>0.052222</td>\n",
       "      <td>0.072122</td>\n",
       "      <td>0.023553</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.023428</td>\n",
       "      <td>0.023323</td>\n",
       "      <td>0.761915</td>\n",
       "      <td>0.024107</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>0.139684</td>\n",
       "      <td>0.096358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.026829</td>\n",
       "      <td>0.064480</td>\n",
       "      <td>0.023571</td>\n",
       "      <td>0.836187</td>\n",
       "      <td>0.058464</td>\n",
       "      <td>0.951090</td>\n",
       "      <td>0.289731</td>\n",
       "      <td>0.657378</td>\n",
       "      <td>0.023741</td>\n",
       "      <td>0.024846</td>\n",
       "      <td>0.023982</td>\n",
       "      <td>0.023357</td>\n",
       "      <td>0.026331</td>\n",
       "      <td>0.048806</td>\n",
       "      <td>0.027089</td>\n",
       "      <td>0.139666</td>\n",
       "      <td>0.368831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.026467</td>\n",
       "      <td>0.029929</td>\n",
       "      <td>0.029836</td>\n",
       "      <td>0.038217</td>\n",
       "      <td>0.028490</td>\n",
       "      <td>0.973691</td>\n",
       "      <td>0.042675</td>\n",
       "      <td>0.062188</td>\n",
       "      <td>0.023841</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.023429</td>\n",
       "      <td>0.023464</td>\n",
       "      <td>0.025826</td>\n",
       "      <td>0.024116</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>0.939358</td>\n",
       "      <td>0.040901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.028014</td>\n",
       "      <td>0.167761</td>\n",
       "      <td>0.023569</td>\n",
       "      <td>0.827623</td>\n",
       "      <td>0.197046</td>\n",
       "      <td>0.936367</td>\n",
       "      <td>0.679081</td>\n",
       "      <td>0.843429</td>\n",
       "      <td>0.023703</td>\n",
       "      <td>0.025242</td>\n",
       "      <td>0.024960</td>\n",
       "      <td>0.023387</td>\n",
       "      <td>0.026021</td>\n",
       "      <td>0.065388</td>\n",
       "      <td>0.036447</td>\n",
       "      <td>0.157439</td>\n",
       "      <td>0.244890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.036359</td>\n",
       "      <td>0.078680</td>\n",
       "      <td>0.024996</td>\n",
       "      <td>0.039607</td>\n",
       "      <td>0.097285</td>\n",
       "      <td>0.940308</td>\n",
       "      <td>0.325971</td>\n",
       "      <td>0.759859</td>\n",
       "      <td>0.024738</td>\n",
       "      <td>0.023617</td>\n",
       "      <td>0.025404</td>\n",
       "      <td>0.024913</td>\n",
       "      <td>0.025929</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>0.026063</td>\n",
       "      <td>0.925171</td>\n",
       "      <td>0.076810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.037287</td>\n",
       "      <td>0.115312</td>\n",
       "      <td>0.023663</td>\n",
       "      <td>0.466347</td>\n",
       "      <td>0.083027</td>\n",
       "      <td>0.896798</td>\n",
       "      <td>0.250375</td>\n",
       "      <td>0.558125</td>\n",
       "      <td>0.024002</td>\n",
       "      <td>0.057322</td>\n",
       "      <td>0.023985</td>\n",
       "      <td>0.023388</td>\n",
       "      <td>0.030580</td>\n",
       "      <td>0.095075</td>\n",
       "      <td>0.045467</td>\n",
       "      <td>0.438269</td>\n",
       "      <td>0.628010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.028257</td>\n",
       "      <td>0.033676</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.040136</td>\n",
       "      <td>0.028731</td>\n",
       "      <td>0.973593</td>\n",
       "      <td>0.049844</td>\n",
       "      <td>0.077360</td>\n",
       "      <td>0.024522</td>\n",
       "      <td>0.023559</td>\n",
       "      <td>0.023464</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.026091</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>0.023336</td>\n",
       "      <td>0.934287</td>\n",
       "      <td>0.071088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40639</th>\n",
       "      <td>0.026952</td>\n",
       "      <td>0.048452</td>\n",
       "      <td>0.056186</td>\n",
       "      <td>0.038545</td>\n",
       "      <td>0.032860</td>\n",
       "      <td>0.973650</td>\n",
       "      <td>0.070436</td>\n",
       "      <td>0.121645</td>\n",
       "      <td>0.039139</td>\n",
       "      <td>0.023645</td>\n",
       "      <td>0.024256</td>\n",
       "      <td>0.033749</td>\n",
       "      <td>0.025834</td>\n",
       "      <td>0.027629</td>\n",
       "      <td>0.023420</td>\n",
       "      <td>0.938192</td>\n",
       "      <td>0.149573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40640</th>\n",
       "      <td>0.028536</td>\n",
       "      <td>0.054736</td>\n",
       "      <td>0.023869</td>\n",
       "      <td>0.580435</td>\n",
       "      <td>0.041291</td>\n",
       "      <td>0.828733</td>\n",
       "      <td>0.090608</td>\n",
       "      <td>0.176166</td>\n",
       "      <td>0.023876</td>\n",
       "      <td>0.023904</td>\n",
       "      <td>0.024296</td>\n",
       "      <td>0.023467</td>\n",
       "      <td>0.304299</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>0.023793</td>\n",
       "      <td>0.143839</td>\n",
       "      <td>0.098606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40641</th>\n",
       "      <td>0.029456</td>\n",
       "      <td>0.165451</td>\n",
       "      <td>0.023865</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>0.122506</td>\n",
       "      <td>0.973051</td>\n",
       "      <td>0.320998</td>\n",
       "      <td>0.591066</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>0.036382</td>\n",
       "      <td>0.027301</td>\n",
       "      <td>0.024232</td>\n",
       "      <td>0.025828</td>\n",
       "      <td>0.059113</td>\n",
       "      <td>0.024413</td>\n",
       "      <td>0.926547</td>\n",
       "      <td>0.378288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40642</th>\n",
       "      <td>0.031696</td>\n",
       "      <td>0.083899</td>\n",
       "      <td>0.023621</td>\n",
       "      <td>0.040206</td>\n",
       "      <td>0.170890</td>\n",
       "      <td>0.949592</td>\n",
       "      <td>0.425426</td>\n",
       "      <td>0.546491</td>\n",
       "      <td>0.024231</td>\n",
       "      <td>0.086729</td>\n",
       "      <td>0.023542</td>\n",
       "      <td>0.023331</td>\n",
       "      <td>0.026099</td>\n",
       "      <td>0.070253</td>\n",
       "      <td>0.031329</td>\n",
       "      <td>0.931959</td>\n",
       "      <td>0.603703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40643</th>\n",
       "      <td>0.027588</td>\n",
       "      <td>0.363593</td>\n",
       "      <td>0.024138</td>\n",
       "      <td>0.727910</td>\n",
       "      <td>0.130794</td>\n",
       "      <td>0.973628</td>\n",
       "      <td>0.280240</td>\n",
       "      <td>0.672507</td>\n",
       "      <td>0.030370</td>\n",
       "      <td>0.026599</td>\n",
       "      <td>0.037096</td>\n",
       "      <td>0.025081</td>\n",
       "      <td>0.025830</td>\n",
       "      <td>0.042016</td>\n",
       "      <td>0.024151</td>\n",
       "      <td>0.278968</td>\n",
       "      <td>0.250373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40644</th>\n",
       "      <td>0.026476</td>\n",
       "      <td>0.029968</td>\n",
       "      <td>0.033559</td>\n",
       "      <td>0.038229</td>\n",
       "      <td>0.028166</td>\n",
       "      <td>0.973695</td>\n",
       "      <td>0.041451</td>\n",
       "      <td>0.061627</td>\n",
       "      <td>0.023809</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.023429</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.025827</td>\n",
       "      <td>0.024155</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>0.939305</td>\n",
       "      <td>0.041083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40645</th>\n",
       "      <td>0.080867</td>\n",
       "      <td>0.029889</td>\n",
       "      <td>0.023557</td>\n",
       "      <td>0.038312</td>\n",
       "      <td>0.028222</td>\n",
       "      <td>0.259827</td>\n",
       "      <td>0.043362</td>\n",
       "      <td>0.063785</td>\n",
       "      <td>0.023553</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.023428</td>\n",
       "      <td>0.023323</td>\n",
       "      <td>0.760224</td>\n",
       "      <td>0.024087</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>0.140233</td>\n",
       "      <td>0.049925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40646</th>\n",
       "      <td>0.027812</td>\n",
       "      <td>0.055754</td>\n",
       "      <td>0.038502</td>\n",
       "      <td>0.040195</td>\n",
       "      <td>0.030522</td>\n",
       "      <td>0.973083</td>\n",
       "      <td>0.056863</td>\n",
       "      <td>0.127779</td>\n",
       "      <td>0.025447</td>\n",
       "      <td>0.023601</td>\n",
       "      <td>0.023944</td>\n",
       "      <td>0.026856</td>\n",
       "      <td>0.026048</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.023359</td>\n",
       "      <td>0.935587</td>\n",
       "      <td>0.093507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40647</th>\n",
       "      <td>0.026482</td>\n",
       "      <td>0.031299</td>\n",
       "      <td>0.057323</td>\n",
       "      <td>0.038307</td>\n",
       "      <td>0.028793</td>\n",
       "      <td>0.973697</td>\n",
       "      <td>0.045253</td>\n",
       "      <td>0.065024</td>\n",
       "      <td>0.026802</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.023449</td>\n",
       "      <td>0.026178</td>\n",
       "      <td>0.025828</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.023329</td>\n",
       "      <td>0.939298</td>\n",
       "      <td>0.052710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40648</th>\n",
       "      <td>0.026559</td>\n",
       "      <td>0.030050</td>\n",
       "      <td>0.030579</td>\n",
       "      <td>0.038225</td>\n",
       "      <td>0.028419</td>\n",
       "      <td>0.973683</td>\n",
       "      <td>0.042387</td>\n",
       "      <td>0.062468</td>\n",
       "      <td>0.023946</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.023432</td>\n",
       "      <td>0.023647</td>\n",
       "      <td>0.025828</td>\n",
       "      <td>0.024111</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>0.939179</td>\n",
       "      <td>0.042132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40649</th>\n",
       "      <td>0.039772</td>\n",
       "      <td>0.159098</td>\n",
       "      <td>0.023784</td>\n",
       "      <td>0.374916</td>\n",
       "      <td>0.126542</td>\n",
       "      <td>0.964123</td>\n",
       "      <td>0.391240</td>\n",
       "      <td>0.719271</td>\n",
       "      <td>0.024359</td>\n",
       "      <td>0.026181</td>\n",
       "      <td>0.026126</td>\n",
       "      <td>0.023632</td>\n",
       "      <td>0.026361</td>\n",
       "      <td>0.050262</td>\n",
       "      <td>0.027436</td>\n",
       "      <td>0.540544</td>\n",
       "      <td>0.269518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40650</th>\n",
       "      <td>0.239604</td>\n",
       "      <td>0.228080</td>\n",
       "      <td>0.024016</td>\n",
       "      <td>0.044996</td>\n",
       "      <td>0.153333</td>\n",
       "      <td>0.972223</td>\n",
       "      <td>0.436424</td>\n",
       "      <td>0.710593</td>\n",
       "      <td>0.025089</td>\n",
       "      <td>0.023802</td>\n",
       "      <td>0.028680</td>\n",
       "      <td>0.023638</td>\n",
       "      <td>0.025905</td>\n",
       "      <td>0.034206</td>\n",
       "      <td>0.023630</td>\n",
       "      <td>0.783645</td>\n",
       "      <td>0.358493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40651</th>\n",
       "      <td>0.059737</td>\n",
       "      <td>0.065481</td>\n",
       "      <td>0.027012</td>\n",
       "      <td>0.042416</td>\n",
       "      <td>0.030357</td>\n",
       "      <td>0.973196</td>\n",
       "      <td>0.055602</td>\n",
       "      <td>0.138915</td>\n",
       "      <td>0.023942</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>0.023846</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.026129</td>\n",
       "      <td>0.030711</td>\n",
       "      <td>0.023343</td>\n",
       "      <td>0.889976</td>\n",
       "      <td>0.123188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40652</th>\n",
       "      <td>0.327070</td>\n",
       "      <td>0.128081</td>\n",
       "      <td>0.023633</td>\n",
       "      <td>0.068717</td>\n",
       "      <td>0.103012</td>\n",
       "      <td>0.954013</td>\n",
       "      <td>0.460802</td>\n",
       "      <td>0.796944</td>\n",
       "      <td>0.023773</td>\n",
       "      <td>0.023624</td>\n",
       "      <td>0.024369</td>\n",
       "      <td>0.023424</td>\n",
       "      <td>0.026678</td>\n",
       "      <td>0.036922</td>\n",
       "      <td>0.023930</td>\n",
       "      <td>0.602948</td>\n",
       "      <td>0.243032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40653</th>\n",
       "      <td>0.026517</td>\n",
       "      <td>0.030048</td>\n",
       "      <td>0.028805</td>\n",
       "      <td>0.038272</td>\n",
       "      <td>0.028337</td>\n",
       "      <td>0.973668</td>\n",
       "      <td>0.042466</td>\n",
       "      <td>0.062733</td>\n",
       "      <td>0.023848</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>0.023442</td>\n",
       "      <td>0.025831</td>\n",
       "      <td>0.024145</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>0.939215</td>\n",
       "      <td>0.043369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40654</th>\n",
       "      <td>0.027419</td>\n",
       "      <td>0.188084</td>\n",
       "      <td>0.023895</td>\n",
       "      <td>0.041623</td>\n",
       "      <td>0.709942</td>\n",
       "      <td>0.969738</td>\n",
       "      <td>0.758520</td>\n",
       "      <td>0.623919</td>\n",
       "      <td>0.038250</td>\n",
       "      <td>0.039478</td>\n",
       "      <td>0.034046</td>\n",
       "      <td>0.023872</td>\n",
       "      <td>0.025825</td>\n",
       "      <td>0.060545</td>\n",
       "      <td>0.028660</td>\n",
       "      <td>0.936776</td>\n",
       "      <td>0.180368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40655</th>\n",
       "      <td>0.026896</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>0.033788</td>\n",
       "      <td>0.038611</td>\n",
       "      <td>0.028940</td>\n",
       "      <td>0.973661</td>\n",
       "      <td>0.055222</td>\n",
       "      <td>0.074867</td>\n",
       "      <td>0.025853</td>\n",
       "      <td>0.023562</td>\n",
       "      <td>0.023457</td>\n",
       "      <td>0.024362</td>\n",
       "      <td>0.025846</td>\n",
       "      <td>0.024438</td>\n",
       "      <td>0.023331</td>\n",
       "      <td>0.938601</td>\n",
       "      <td>0.084582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40656</th>\n",
       "      <td>0.032842</td>\n",
       "      <td>0.049795</td>\n",
       "      <td>0.023594</td>\n",
       "      <td>0.041149</td>\n",
       "      <td>0.532339</td>\n",
       "      <td>0.811291</td>\n",
       "      <td>0.695662</td>\n",
       "      <td>0.454798</td>\n",
       "      <td>0.023926</td>\n",
       "      <td>0.063077</td>\n",
       "      <td>0.023569</td>\n",
       "      <td>0.023346</td>\n",
       "      <td>0.025988</td>\n",
       "      <td>0.156565</td>\n",
       "      <td>0.059699</td>\n",
       "      <td>0.929828</td>\n",
       "      <td>0.269143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40657</th>\n",
       "      <td>0.026657</td>\n",
       "      <td>0.031369</td>\n",
       "      <td>0.048996</td>\n",
       "      <td>0.038351</td>\n",
       "      <td>0.028729</td>\n",
       "      <td>0.973634</td>\n",
       "      <td>0.044931</td>\n",
       "      <td>0.067405</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.023556</td>\n",
       "      <td>0.023475</td>\n",
       "      <td>0.025952</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>0.024548</td>\n",
       "      <td>0.023332</td>\n",
       "      <td>0.938705</td>\n",
       "      <td>0.052330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40658</th>\n",
       "      <td>0.060424</td>\n",
       "      <td>0.152790</td>\n",
       "      <td>0.023614</td>\n",
       "      <td>0.043830</td>\n",
       "      <td>0.402305</td>\n",
       "      <td>0.965423</td>\n",
       "      <td>0.605490</td>\n",
       "      <td>0.769644</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.025317</td>\n",
       "      <td>0.025940</td>\n",
       "      <td>0.023397</td>\n",
       "      <td>0.025852</td>\n",
       "      <td>0.048137</td>\n",
       "      <td>0.030005</td>\n",
       "      <td>0.893663</td>\n",
       "      <td>0.281517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40659</th>\n",
       "      <td>0.026461</td>\n",
       "      <td>0.195451</td>\n",
       "      <td>0.023944</td>\n",
       "      <td>0.837882</td>\n",
       "      <td>0.071511</td>\n",
       "      <td>0.973649</td>\n",
       "      <td>0.263485</td>\n",
       "      <td>0.451597</td>\n",
       "      <td>0.028344</td>\n",
       "      <td>0.024774</td>\n",
       "      <td>0.030438</td>\n",
       "      <td>0.025224</td>\n",
       "      <td>0.025829</td>\n",
       "      <td>0.029892</td>\n",
       "      <td>0.024727</td>\n",
       "      <td>0.139569</td>\n",
       "      <td>0.283025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40660</th>\n",
       "      <td>0.026507</td>\n",
       "      <td>0.030103</td>\n",
       "      <td>0.079041</td>\n",
       "      <td>0.038224</td>\n",
       "      <td>0.028817</td>\n",
       "      <td>0.973676</td>\n",
       "      <td>0.042651</td>\n",
       "      <td>0.062194</td>\n",
       "      <td>0.025431</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.023436</td>\n",
       "      <td>0.025627</td>\n",
       "      <td>0.025827</td>\n",
       "      <td>0.024523</td>\n",
       "      <td>0.023329</td>\n",
       "      <td>0.939307</td>\n",
       "      <td>0.040931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40661</th>\n",
       "      <td>0.042816</td>\n",
       "      <td>0.168004</td>\n",
       "      <td>0.032055</td>\n",
       "      <td>0.048604</td>\n",
       "      <td>0.042958</td>\n",
       "      <td>0.973541</td>\n",
       "      <td>0.151026</td>\n",
       "      <td>0.292624</td>\n",
       "      <td>0.034237</td>\n",
       "      <td>0.024222</td>\n",
       "      <td>0.026984</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.025867</td>\n",
       "      <td>0.036450</td>\n",
       "      <td>0.023722</td>\n",
       "      <td>0.911181</td>\n",
       "      <td>0.347330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40662</th>\n",
       "      <td>0.027111</td>\n",
       "      <td>0.284169</td>\n",
       "      <td>0.025626</td>\n",
       "      <td>0.041755</td>\n",
       "      <td>0.182286</td>\n",
       "      <td>0.973482</td>\n",
       "      <td>0.372085</td>\n",
       "      <td>0.632887</td>\n",
       "      <td>0.038916</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>0.036302</td>\n",
       "      <td>0.025440</td>\n",
       "      <td>0.025828</td>\n",
       "      <td>0.047381</td>\n",
       "      <td>0.025647</td>\n",
       "      <td>0.934759</td>\n",
       "      <td>0.274914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40663</th>\n",
       "      <td>0.100688</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.024345</td>\n",
       "      <td>0.041054</td>\n",
       "      <td>0.029188</td>\n",
       "      <td>0.963083</td>\n",
       "      <td>0.053941</td>\n",
       "      <td>0.068447</td>\n",
       "      <td>0.023628</td>\n",
       "      <td>0.023577</td>\n",
       "      <td>0.023433</td>\n",
       "      <td>0.023349</td>\n",
       "      <td>0.107112</td>\n",
       "      <td>0.024582</td>\n",
       "      <td>0.023337</td>\n",
       "      <td>0.705486</td>\n",
       "      <td>0.331099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40664</th>\n",
       "      <td>0.026919</td>\n",
       "      <td>0.030835</td>\n",
       "      <td>0.040781</td>\n",
       "      <td>0.038250</td>\n",
       "      <td>0.029045</td>\n",
       "      <td>0.973672</td>\n",
       "      <td>0.048084</td>\n",
       "      <td>0.067965</td>\n",
       "      <td>0.026271</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.023449</td>\n",
       "      <td>0.023980</td>\n",
       "      <td>0.025829</td>\n",
       "      <td>0.024419</td>\n",
       "      <td>0.023329</td>\n",
       "      <td>0.938828</td>\n",
       "      <td>0.060141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40665</th>\n",
       "      <td>0.027359</td>\n",
       "      <td>0.105948</td>\n",
       "      <td>0.024657</td>\n",
       "      <td>0.038459</td>\n",
       "      <td>0.132122</td>\n",
       "      <td>0.972086</td>\n",
       "      <td>0.557836</td>\n",
       "      <td>0.290480</td>\n",
       "      <td>0.047391</td>\n",
       "      <td>0.027169</td>\n",
       "      <td>0.023862</td>\n",
       "      <td>0.023527</td>\n",
       "      <td>0.026061</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.026281</td>\n",
       "      <td>0.937213</td>\n",
       "      <td>0.604580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40666</th>\n",
       "      <td>0.030167</td>\n",
       "      <td>0.280468</td>\n",
       "      <td>0.024468</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>0.117691</td>\n",
       "      <td>0.972425</td>\n",
       "      <td>0.222067</td>\n",
       "      <td>0.737109</td>\n",
       "      <td>0.025811</td>\n",
       "      <td>0.023885</td>\n",
       "      <td>0.033314</td>\n",
       "      <td>0.024763</td>\n",
       "      <td>0.025832</td>\n",
       "      <td>0.067036</td>\n",
       "      <td>0.025337</td>\n",
       "      <td>0.922108</td>\n",
       "      <td>0.131399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40667</th>\n",
       "      <td>0.026504</td>\n",
       "      <td>0.085287</td>\n",
       "      <td>0.023951</td>\n",
       "      <td>0.837729</td>\n",
       "      <td>0.032119</td>\n",
       "      <td>0.973560</td>\n",
       "      <td>0.059059</td>\n",
       "      <td>0.128048</td>\n",
       "      <td>0.024639</td>\n",
       "      <td>0.023609</td>\n",
       "      <td>0.024789</td>\n",
       "      <td>0.024012</td>\n",
       "      <td>0.025857</td>\n",
       "      <td>0.025918</td>\n",
       "      <td>0.023511</td>\n",
       "      <td>0.139488</td>\n",
       "      <td>0.130952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40668</th>\n",
       "      <td>0.026467</td>\n",
       "      <td>0.029938</td>\n",
       "      <td>0.026871</td>\n",
       "      <td>0.038222</td>\n",
       "      <td>0.028154</td>\n",
       "      <td>0.973694</td>\n",
       "      <td>0.041449</td>\n",
       "      <td>0.061621</td>\n",
       "      <td>0.023704</td>\n",
       "      <td>0.023555</td>\n",
       "      <td>0.023429</td>\n",
       "      <td>0.023420</td>\n",
       "      <td>0.025826</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>0.939338</td>\n",
       "      <td>0.040780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40669 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           haze  cultivation  blooming  partly_cloudy  habitation   primary  \\\n",
       "0      0.028700     0.030620  0.036162       0.038355    0.028957  0.973636   \n",
       "1      0.026938     0.052194  0.040162       0.040805    0.030847  0.973635   \n",
       "2      0.026471     0.063229  0.024015       0.836597    0.036900  0.972833   \n",
       "3      0.031146     0.348414  0.037752       0.041573    0.037574  0.973624   \n",
       "4      0.027897     0.043863  0.023641       0.625688    0.036407  0.822585   \n",
       "5      0.026563     0.030426  0.030768       0.038251    0.028648  0.973687   \n",
       "6      0.057428     0.355900  0.025466       0.265411    0.107987  0.972856   \n",
       "7      0.030707     0.036791  0.023561       0.040037    0.763600  0.790682   \n",
       "8      0.026597     0.030199  0.027406       0.038283    0.028414  0.973676   \n",
       "9      0.726279     0.141329  0.024536       0.048267    0.044932  0.972255   \n",
       "10     0.026513     0.101052  0.024441       0.837893    0.041098  0.973510   \n",
       "11     0.026822     0.627410  0.028353       0.040099    0.186354  0.973677   \n",
       "12     0.095917     0.030959  0.023558       0.059999    0.029409  0.266209   \n",
       "13     0.027575     0.489600  0.031541       0.041004    0.114407  0.973496   \n",
       "14     0.176140     0.239627  0.028866       0.050856    0.042147  0.973131   \n",
       "15     0.026547     0.038334  0.052213       0.038435    0.029978  0.973650   \n",
       "16     0.026997     0.261919  0.024909       0.039278    0.538030  0.973099   \n",
       "17     0.028742     0.044362  0.034703       0.762553    0.031924  0.972069   \n",
       "18     0.128331     0.032971  0.026587       0.040645    0.028764  0.973321   \n",
       "19     0.026732     0.064501  0.036798       0.038383    0.073407  0.973491   \n",
       "20     0.026673     0.080784  0.025852       0.038353    0.083301  0.973598   \n",
       "21     0.047460     0.053717  0.023617       0.039255    0.055500  0.918591   \n",
       "22     0.050006     0.228246  0.023652       0.132060    0.367833  0.965097   \n",
       "23     0.124646     0.031074  0.023556       0.039011    0.028769  0.262284   \n",
       "24     0.026829     0.064480  0.023571       0.836187    0.058464  0.951090   \n",
       "25     0.026467     0.029929  0.029836       0.038217    0.028490  0.973691   \n",
       "26     0.028014     0.167761  0.023569       0.827623    0.197046  0.936367   \n",
       "27     0.036359     0.078680  0.024996       0.039607    0.097285  0.940308   \n",
       "28     0.037287     0.115312  0.023663       0.466347    0.083027  0.896798   \n",
       "29     0.028257     0.033676  0.029412       0.040136    0.028731  0.973593   \n",
       "...         ...          ...       ...            ...         ...       ...   \n",
       "40639  0.026952     0.048452  0.056186       0.038545    0.032860  0.973650   \n",
       "40640  0.028536     0.054736  0.023869       0.580435    0.041291  0.828733   \n",
       "40641  0.029456     0.165451  0.023865       0.049967    0.122506  0.973051   \n",
       "40642  0.031696     0.083899  0.023621       0.040206    0.170890  0.949592   \n",
       "40643  0.027588     0.363593  0.024138       0.727910    0.130794  0.973628   \n",
       "40644  0.026476     0.029968  0.033559       0.038229    0.028166  0.973695   \n",
       "40645  0.080867     0.029889  0.023557       0.038312    0.028222  0.259827   \n",
       "40646  0.027812     0.055754  0.038502       0.040195    0.030522  0.973083   \n",
       "40647  0.026482     0.031299  0.057323       0.038307    0.028793  0.973697   \n",
       "40648  0.026559     0.030050  0.030579       0.038225    0.028419  0.973683   \n",
       "40649  0.039772     0.159098  0.023784       0.374916    0.126542  0.964123   \n",
       "40650  0.239604     0.228080  0.024016       0.044996    0.153333  0.972223   \n",
       "40651  0.059737     0.065481  0.027012       0.042416    0.030357  0.973196   \n",
       "40652  0.327070     0.128081  0.023633       0.068717    0.103012  0.954013   \n",
       "40653  0.026517     0.030048  0.028805       0.038272    0.028337  0.973668   \n",
       "40654  0.027419     0.188084  0.023895       0.041623    0.709942  0.969738   \n",
       "40655  0.026896     0.032660  0.033788       0.038611    0.028940  0.973661   \n",
       "40656  0.032842     0.049795  0.023594       0.041149    0.532339  0.811291   \n",
       "40657  0.026657     0.031369  0.048996       0.038351    0.028729  0.973634   \n",
       "40658  0.060424     0.152790  0.023614       0.043830    0.402305  0.965423   \n",
       "40659  0.026461     0.195451  0.023944       0.837882    0.071511  0.973649   \n",
       "40660  0.026507     0.030103  0.079041       0.038224    0.028817  0.973676   \n",
       "40661  0.042816     0.168004  0.032055       0.048604    0.042958  0.973541   \n",
       "40662  0.027111     0.284169  0.025626       0.041755    0.182286  0.973482   \n",
       "40663  0.100688     0.031193  0.024345       0.041054    0.029188  0.963083   \n",
       "40664  0.026919     0.030835  0.040781       0.038250    0.029045  0.973672   \n",
       "40665  0.027359     0.105948  0.024657       0.038459    0.132122  0.972086   \n",
       "40666  0.030167     0.280468  0.024468       0.059057    0.117691  0.972425   \n",
       "40667  0.026504     0.085287  0.023951       0.837729    0.032119  0.973560   \n",
       "40668  0.026467     0.029938  0.026871       0.038222    0.028154  0.973694   \n",
       "\n",
       "           road  agriculture  selective_logging  artisinal_mine  slash_burn  \\\n",
       "0      0.044871     0.065092           0.024508        0.023555    0.023439   \n",
       "1      0.064669     0.106115           0.039138        0.023585    0.023720   \n",
       "2      0.073065     0.128349           0.024471        0.023968    0.024879   \n",
       "3      0.060415     0.317086           0.031035        0.023622    0.032051   \n",
       "4      0.096402     0.154245           0.023595        0.023720    0.023486   \n",
       "5      0.046380     0.065224           0.024200        0.023555    0.023432   \n",
       "6      0.201706     0.642872           0.027171        0.024039    0.041086   \n",
       "7      0.818932     0.270763           0.024248        0.048928    0.023457   \n",
       "8      0.043991     0.064822           0.023731        0.023555    0.023430   \n",
       "9      0.164649     0.409359           0.024145        0.023572    0.024541   \n",
       "10     0.126887     0.271982           0.025435        0.023867    0.026314   \n",
       "11     0.172807     0.632966           0.052170        0.025100    0.070224   \n",
       "12     0.056645     0.073978           0.023554        0.023559    0.023429   \n",
       "13     0.172647     0.576776           0.043732        0.024288    0.041507   \n",
       "14     0.079520     0.376316           0.027081        0.023679    0.027723   \n",
       "15     0.067910     0.099070           0.032017        0.023559    0.023722   \n",
       "16     0.588097     0.804455           0.037558        0.024229    0.067406   \n",
       "17     0.045929     0.084060           0.024943        0.023584    0.023852   \n",
       "18     0.050932     0.075084           0.023789        0.023559    0.023444   \n",
       "19     0.568266     0.172875           0.165742        0.030820    0.024734   \n",
       "20     0.384998     0.225124           0.060468        0.036986    0.025090   \n",
       "21     0.234642     0.410502           0.023742        0.025508    0.023522   \n",
       "22     0.661998     0.820809           0.025340        0.024086    0.029850   \n",
       "23     0.052222     0.072122           0.023553        0.023555    0.023428   \n",
       "24     0.289731     0.657378           0.023741        0.024846    0.023982   \n",
       "25     0.042675     0.062188           0.023841        0.023555    0.023429   \n",
       "26     0.679081     0.843429           0.023703        0.025242    0.024960   \n",
       "27     0.325971     0.759859           0.024738        0.023617    0.025404   \n",
       "28     0.250375     0.558125           0.024002        0.057322    0.023985   \n",
       "29     0.049844     0.077360           0.024522        0.023559    0.023464   \n",
       "...         ...          ...                ...             ...         ...   \n",
       "40639  0.070436     0.121645           0.039139        0.023645    0.024256   \n",
       "40640  0.090608     0.176166           0.023876        0.023904    0.024296   \n",
       "40641  0.320998     0.591066           0.029126        0.036382    0.027301   \n",
       "40642  0.425426     0.546491           0.024231        0.086729    0.023542   \n",
       "40643  0.280240     0.672507           0.030370        0.026599    0.037096   \n",
       "40644  0.041451     0.061627           0.023809        0.023555    0.023429   \n",
       "40645  0.043362     0.063785           0.023553        0.023555    0.023428   \n",
       "40646  0.056863     0.127779           0.025447        0.023601    0.023944   \n",
       "40647  0.045253     0.065024           0.026802        0.023555    0.023449   \n",
       "40648  0.042387     0.062468           0.023946        0.023555    0.023432   \n",
       "40649  0.391240     0.719271           0.024359        0.026181    0.026126   \n",
       "40650  0.436424     0.710593           0.025089        0.023802    0.028680   \n",
       "40651  0.055602     0.138915           0.023942        0.023575    0.023846   \n",
       "40652  0.460802     0.796944           0.023773        0.023624    0.024369   \n",
       "40653  0.042466     0.062733           0.023848        0.023555    0.023431   \n",
       "40654  0.758520     0.623919           0.038250        0.039478    0.034046   \n",
       "40655  0.055222     0.074867           0.025853        0.023562    0.023457   \n",
       "40656  0.695662     0.454798           0.023926        0.063077    0.023569   \n",
       "40657  0.044931     0.067405           0.026000        0.023556    0.023475   \n",
       "40658  0.605490     0.769644           0.024375        0.025317    0.025940   \n",
       "40659  0.263485     0.451597           0.028344        0.024774    0.030438   \n",
       "40660  0.042651     0.062194           0.025431        0.023555    0.023436   \n",
       "40661  0.151026     0.292624           0.034237        0.024222    0.026984   \n",
       "40662  0.372085     0.632887           0.038916        0.025608    0.036302   \n",
       "40663  0.053941     0.068447           0.023628        0.023577    0.023433   \n",
       "40664  0.048084     0.067965           0.026271        0.023555    0.023449   \n",
       "40665  0.557836     0.290480           0.047391        0.027169    0.023862   \n",
       "40666  0.222067     0.737109           0.025811        0.023885    0.033314   \n",
       "40667  0.059059     0.128048           0.024639        0.023609    0.024789   \n",
       "40668  0.041449     0.061621           0.023704        0.023555    0.023429   \n",
       "\n",
       "       blow_down    cloudy  bare_ground  conventional_mine     clear     water  \n",
       "0       0.023847  0.025835     0.024383           0.023329  0.937296  0.048925  \n",
       "1       0.034003  0.025857     0.025599           0.023374  0.935299  0.125093  \n",
       "2       0.024058  0.026394     0.025432           0.023435  0.139797  0.130319  \n",
       "3       0.030560  0.025854     0.034290           0.023419  0.932555  0.110725  \n",
       "4       0.023383  0.269760     0.028236           0.023494  0.139999  0.144990  \n",
       "5       0.023834  0.025831     0.024158           0.023328  0.939171  0.049384  \n",
       "6       0.026417  0.026000     0.039254           0.023888  0.503907  0.218843  \n",
       "7       0.023327  0.025879     0.060152           0.035618  0.930863  0.173067  \n",
       "8       0.023494  0.025827     0.024164           0.023328  0.939115  0.044568  \n",
       "9       0.023517  0.026720     0.028662           0.023430  0.309497  0.298286  \n",
       "10      0.025624  0.025849     0.026873           0.023519  0.139528  0.155376  \n",
       "11      0.029096  0.025826     0.045982           0.024104  0.936886  0.199267  \n",
       "12      0.023323  0.785729     0.024198           0.023333  0.140228  0.076852  \n",
       "13      0.028966  0.025829     0.043799           0.023892  0.935993  0.154409  \n",
       "14      0.024544  0.026030     0.041079           0.023481  0.802677  0.222147  \n",
       "15      0.029002  0.025834     0.025654           0.023345  0.938993  0.081904  \n",
       "16      0.030308  0.025825     0.052378           0.024861  0.937726  0.099728  \n",
       "17      0.027657  0.026415     0.025989           0.023392  0.302940  0.057746  \n",
       "18      0.023470  0.026166     0.025186           0.023334  0.826794  0.121737  \n",
       "19      0.027605  0.025830     0.028078           0.024864  0.938903  0.601366  \n",
       "20      0.025555  0.025831     0.043263           0.028474  0.938962  0.649110  \n",
       "21      0.023332  0.042833     0.049230           0.024880  0.896248  0.711910  \n",
       "22      0.023568  0.025881     0.041679           0.024731  0.755792  0.135235  \n",
       "23      0.023323  0.761915     0.024107           0.023328  0.139684  0.096358  \n",
       "24      0.023357  0.026331     0.048806           0.027089  0.139666  0.368831  \n",
       "25      0.023464  0.025826     0.024116           0.023328  0.939358  0.040901  \n",
       "26      0.023387  0.026021     0.065388           0.036447  0.157439  0.244890  \n",
       "27      0.024913  0.025929     0.142301           0.026063  0.925171  0.076810  \n",
       "28      0.023388  0.030580     0.095075           0.045467  0.438269  0.628010  \n",
       "29      0.023671  0.026091     0.024583           0.023336  0.934287  0.071088  \n",
       "...          ...       ...          ...                ...       ...       ...  \n",
       "40639   0.033749  0.025834     0.027629           0.023420  0.938192  0.149573  \n",
       "40640   0.023467  0.304299     0.027108           0.023793  0.143839  0.098606  \n",
       "40641   0.024232  0.025828     0.059113           0.024413  0.926547  0.378288  \n",
       "40642   0.023331  0.026099     0.070253           0.031329  0.931959  0.603703  \n",
       "40643   0.025081  0.025830     0.042016           0.024151  0.278968  0.250373  \n",
       "40644   0.023548  0.025827     0.024155           0.023328  0.939305  0.041083  \n",
       "40645   0.023323  0.760224     0.024087           0.023328  0.140233  0.049925  \n",
       "40646   0.026856  0.026048     0.027731           0.023359  0.935587  0.093507  \n",
       "40647   0.026178  0.025828     0.024498           0.023329  0.939298  0.052710  \n",
       "40648   0.023647  0.025828     0.024111           0.023328  0.939179  0.042132  \n",
       "40649   0.023632  0.026361     0.050262           0.027436  0.540544  0.269518  \n",
       "40650   0.023638  0.025905     0.034206           0.023630  0.783645  0.358493  \n",
       "40651   0.024390  0.026129     0.030711           0.023343  0.889976  0.123188  \n",
       "40652   0.023424  0.026678     0.036922           0.023930  0.602948  0.243032  \n",
       "40653   0.023442  0.025831     0.024145           0.023328  0.939215  0.043369  \n",
       "40654   0.023872  0.025825     0.060545           0.028660  0.936776  0.180368  \n",
       "40655   0.024362  0.025846     0.024438           0.023331  0.938601  0.084582  \n",
       "40656   0.023346  0.025988     0.156565           0.059699  0.929828  0.269143  \n",
       "40657   0.025952  0.025847     0.024548           0.023332  0.938705  0.052330  \n",
       "40658   0.023397  0.025852     0.048137           0.030005  0.893663  0.281517  \n",
       "40659   0.025224  0.025829     0.029892           0.024727  0.139569  0.283025  \n",
       "40660   0.025627  0.025827     0.024523           0.023329  0.939307  0.040931  \n",
       "40661   0.025696  0.025867     0.036450           0.023722  0.911181  0.347330  \n",
       "40662   0.025440  0.025828     0.047381           0.025647  0.934759  0.274914  \n",
       "40663   0.023349  0.107112     0.024582           0.023337  0.705486  0.331099  \n",
       "40664   0.023980  0.025829     0.024419           0.023329  0.938828  0.060141  \n",
       "40665   0.023527  0.026061     0.051400           0.026281  0.937213  0.604580  \n",
       "40666   0.024763  0.025832     0.067036           0.025337  0.922108  0.131399  \n",
       "40667   0.024012  0.025857     0.025918           0.023511  0.139488  0.130952  \n",
       "40668   0.023420  0.025826     0.024118           0.023328  0.939338  0.040780  \n",
       "\n",
       "[40669 rows x 17 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(result, columns = labels)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40669/40669 [01:01<00:00, 656.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "preds = []\n",
    "for i in tqdm(range(result.shape[0]), miniters=1000):\n",
    "    a = result.ix[[i]]\n",
    "    a = a.apply(lambda x: x > 0.18, axis=1)\n",
    "    a = a.transpose()\n",
    "    a = a.loc[a[i] == True]\n",
    "    ' '.join(list(a.index))\n",
    "    preds.append(' '.join(list(a.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>partly_cloudy primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>cultivation primary agriculture clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>partly_cloudy primary cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_5</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_6</td>\n",
       "      <td>cultivation partly_cloudy primary road agricul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_7</td>\n",
       "      <td>habitation primary road agriculture clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_8</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_9</td>\n",
       "      <td>haze primary agriculture clear water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_10</td>\n",
       "      <td>partly_cloudy primary agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_11</td>\n",
       "      <td>cultivation habitation primary agriculture cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_12</td>\n",
       "      <td>primary cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test_13</td>\n",
       "      <td>cultivation primary agriculture clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test_14</td>\n",
       "      <td>cultivation primary agriculture clear water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test_15</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test_16</td>\n",
       "      <td>cultivation habitation primary road agricultur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test_17</td>\n",
       "      <td>partly_cloudy primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test_18</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test_19</td>\n",
       "      <td>primary road clear water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test_20</td>\n",
       "      <td>primary road agriculture clear water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test_21</td>\n",
       "      <td>primary road agriculture clear water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test_22</td>\n",
       "      <td>cultivation habitation primary road agricultur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test_23</td>\n",
       "      <td>primary cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>test_24</td>\n",
       "      <td>partly_cloudy primary road agriculture water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test_25</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>test_26</td>\n",
       "      <td>partly_cloudy habitation primary road agricult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test_27</td>\n",
       "      <td>primary road agriculture clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>test_28</td>\n",
       "      <td>partly_cloudy primary road agriculture clear w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test_29</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40639</th>\n",
       "      <td>test_40639</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40640</th>\n",
       "      <td>test_40640</td>\n",
       "      <td>partly_cloudy primary cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40641</th>\n",
       "      <td>test_40641</td>\n",
       "      <td>primary road agriculture clear water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40642</th>\n",
       "      <td>test_40642</td>\n",
       "      <td>primary road agriculture clear water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40643</th>\n",
       "      <td>test_40643</td>\n",
       "      <td>cultivation partly_cloudy primary road agricul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40644</th>\n",
       "      <td>test_40644</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40645</th>\n",
       "      <td>test_40645</td>\n",
       "      <td>primary cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40646</th>\n",
       "      <td>test_40646</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40647</th>\n",
       "      <td>test_40647</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40648</th>\n",
       "      <td>test_40648</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40649</th>\n",
       "      <td>test_40649</td>\n",
       "      <td>partly_cloudy primary road agriculture clear w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40650</th>\n",
       "      <td>test_40650</td>\n",
       "      <td>haze cultivation primary road agriculture clea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40651</th>\n",
       "      <td>test_40651</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40652</th>\n",
       "      <td>test_40652</td>\n",
       "      <td>haze primary road agriculture clear water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40653</th>\n",
       "      <td>test_40653</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40654</th>\n",
       "      <td>test_40654</td>\n",
       "      <td>cultivation habitation primary road agricultur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40655</th>\n",
       "      <td>test_40655</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40656</th>\n",
       "      <td>test_40656</td>\n",
       "      <td>habitation primary road agriculture clear water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40657</th>\n",
       "      <td>test_40657</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40658</th>\n",
       "      <td>test_40658</td>\n",
       "      <td>habitation primary road agriculture clear water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40659</th>\n",
       "      <td>test_40659</td>\n",
       "      <td>cultivation partly_cloudy primary road agricul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40660</th>\n",
       "      <td>test_40660</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40661</th>\n",
       "      <td>test_40661</td>\n",
       "      <td>primary agriculture clear water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40662</th>\n",
       "      <td>test_40662</td>\n",
       "      <td>cultivation habitation primary road agricultur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40663</th>\n",
       "      <td>test_40663</td>\n",
       "      <td>primary clear water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40664</th>\n",
       "      <td>test_40664</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40665</th>\n",
       "      <td>test_40665</td>\n",
       "      <td>primary road agriculture clear water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40666</th>\n",
       "      <td>test_40666</td>\n",
       "      <td>cultivation primary road agriculture clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40667</th>\n",
       "      <td>test_40667</td>\n",
       "      <td>partly_cloudy primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40668</th>\n",
       "      <td>test_40668</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40669 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name                                               tags\n",
       "0          test_0                                      primary clear\n",
       "1          test_1                                      primary clear\n",
       "2          test_2                              partly_cloudy primary\n",
       "3          test_3              cultivation primary agriculture clear\n",
       "4          test_4                       partly_cloudy primary cloudy\n",
       "5          test_5                                      primary clear\n",
       "6          test_6  cultivation partly_cloudy primary road agricul...\n",
       "7          test_7          habitation primary road agriculture clear\n",
       "8          test_8                                      primary clear\n",
       "9          test_9               haze primary agriculture clear water\n",
       "10        test_10                  partly_cloudy primary agriculture\n",
       "11        test_11  cultivation habitation primary agriculture cle...\n",
       "12        test_12                                     primary cloudy\n",
       "13        test_13              cultivation primary agriculture clear\n",
       "14        test_14        cultivation primary agriculture clear water\n",
       "15        test_15                                      primary clear\n",
       "16        test_16  cultivation habitation primary road agricultur...\n",
       "17        test_17                        partly_cloudy primary clear\n",
       "18        test_18                                      primary clear\n",
       "19        test_19                           primary road clear water\n",
       "20        test_20               primary road agriculture clear water\n",
       "21        test_21               primary road agriculture clear water\n",
       "22        test_22  cultivation habitation primary road agricultur...\n",
       "23        test_23                                     primary cloudy\n",
       "24        test_24       partly_cloudy primary road agriculture water\n",
       "25        test_25                                      primary clear\n",
       "26        test_26  partly_cloudy habitation primary road agricult...\n",
       "27        test_27                     primary road agriculture clear\n",
       "28        test_28  partly_cloudy primary road agriculture clear w...\n",
       "29        test_29                                      primary clear\n",
       "...           ...                                                ...\n",
       "40639  test_40639                                      primary clear\n",
       "40640  test_40640                       partly_cloudy primary cloudy\n",
       "40641  test_40641               primary road agriculture clear water\n",
       "40642  test_40642               primary road agriculture clear water\n",
       "40643  test_40643  cultivation partly_cloudy primary road agricul...\n",
       "40644  test_40644                                      primary clear\n",
       "40645  test_40645                                     primary cloudy\n",
       "40646  test_40646                                      primary clear\n",
       "40647  test_40647                                      primary clear\n",
       "40648  test_40648                                      primary clear\n",
       "40649  test_40649  partly_cloudy primary road agriculture clear w...\n",
       "40650  test_40650  haze cultivation primary road agriculture clea...\n",
       "40651  test_40651                                      primary clear\n",
       "40652  test_40652          haze primary road agriculture clear water\n",
       "40653  test_40653                                      primary clear\n",
       "40654  test_40654  cultivation habitation primary road agricultur...\n",
       "40655  test_40655                                      primary clear\n",
       "40656  test_40656    habitation primary road agriculture clear water\n",
       "40657  test_40657                                      primary clear\n",
       "40658  test_40658    habitation primary road agriculture clear water\n",
       "40659  test_40659  cultivation partly_cloudy primary road agricul...\n",
       "40660  test_40660                                      primary clear\n",
       "40661  test_40661                    primary agriculture clear water\n",
       "40662  test_40662  cultivation habitation primary road agricultur...\n",
       "40663  test_40663                                primary clear water\n",
       "40664  test_40664                                      primary clear\n",
       "40665  test_40665               primary road agriculture clear water\n",
       "40666  test_40666         cultivation primary road agriculture clear\n",
       "40667  test_40667                              partly_cloudy primary\n",
       "40668  test_40668                                      primary clear\n",
       "\n",
       "[40669 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['tags'] = preds\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.to_csv(RESULT_DIR+'/sub13.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/chicm/ml/cnnpractices/planet'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
